{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cf_xarray\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "\n",
    "# import s1_tools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext rich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r da\n",
    "pc_cube = da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_cube = pc_cube.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_type = \"full\"\n",
    "\n",
    "asf_cube = xr.open_dataset(\n",
    "    f\"../../sentinel1/data/{timeseries_type}_timeseries/intermediate_cubes/s1_asf_clipped_cube.zarr\",\n",
    "    engine=\"zarr\",\n",
    "    chunks=\"auto\",\n",
    "    decode_coords=\"all\",\n",
    ")\n",
    "asf_cube = asf_cube.rename({\"acq_date\": \"time\"})\n",
    "asf_cube = asf_cube.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check CRS metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_cube.rio.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube.rio.crs\n",
    "\n",
    "for variable in asf_cube.data_vars:\n",
    "    print(asf_cube[variable].rio.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset PC timeseries to common elements with ASF time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_acq_dates = asf_cube.time.dt.date.data.tolist()\n",
    "pc_subset = pc_cube.where(pc_cube.time.dt.date.isin(asf_acq_dates), drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to add CRS back in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset = pc_subset.rio.write_crs(pc_cube.rio.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to `xr.DataArray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube = asf_cube.set_coords(\"ls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_da = asf_cube.to_dataarray(dim=\"band\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add CF attrs to `'band'` coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset[\"band\"].attrs = {\n",
    "    \"long_name\": \"Radar polarization\",\n",
    "    \"cf_role\": \"auxiliary_coordinate\",\n",
    "    \"flag_meanings\": \"vv vh\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_da[\"band\"].attrs = {\n",
    "    \"long_name\": \"Radar polarization\",\n",
    "    \"cf_role\": \"auxiliary_coordinate\",\n",
    "    \"flag_meanings\": \"vv vh\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add CF attrs to backscatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset.attrs = {\n",
    "    \"long_name\": \"normalized radar backscatter coefficient\",\n",
    "    \"units\": 1,  # unitless\n",
    "    \"description\": \"Normalized radar backscatter coefficient (gamma naught) for a given polarization band. Unitless until converted to dB or amplitude scale\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_da.attrs = {\n",
    "    \"long_name\": \"normalized radar backscatter coefficient\",\n",
    "    \"units\": 1,  # unitless\n",
    "    \"description\": \"Normalized radar backscatter coefficient (gamma naught) for a given polarization band. Unitless until converted to dB or amplitude scale\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, convert objects from `xr.DataArrays` to `xr.Datasets`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset_ds = pc_subset.to_dataset(dim=\"band\").drop_dims(\"band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_ds = asf_da.to_dataset(dim=\"band\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First approach, use xesmf to regrid projected datasets by making datasets CF compliant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make attrs necessary for CF compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_grid_mapping(ds: xr.Dataset):\n",
    "    crs = pyproj.CRS(ds.rio.crs)\n",
    "\n",
    "    # make grid mapping\n",
    "    grid_mapping = crs.to_cf()\n",
    "    # make coord sys\n",
    "    cs = crs.cs_to_cf()\n",
    "\n",
    "    # make grid mapping var\n",
    "    grid_mapping_var = xr.DataArray(0, attrs=grid_mapping)\n",
    "    # add to ds\n",
    "    ds[\"grid_mapping\"] = grid_mapping_var\n",
    "    # set as coord\n",
    "    ds = ds.set_coords(\"grid_mapping\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube_cf = add_grid_mapping(asf_ds)\n",
    "pc_subset_ds_cf = add_grid_mapping(pc_subset_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check attrs available for cf_xarray to interpret w/ `ds.cf.keys()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube_cf.cf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset_ds_cf.cf.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of how we read the two objects into memory initially (`xr.open_dataset()` for the ASF cube and `stackstac.stack()` for the PC cube), we need to manually add attributes to the x and y coordinate variables of the PC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset_ds_cf.x.attrs = asf_cube_cf.x.attrs\n",
    "pc_subset_ds_cf.y.attrs = asf_cube_cf.y.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add grid mapping attr to x and y coords to point to the grid mapping variable (not sure this is necessary?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset_ds_cf.x.attrs.update({\"grid_mapping\": \"grid_mapping\"})\n",
    "pc_subset_ds_cf.y.attrs.update({\"grid_mapping\": \"grid_mapping\"})\n",
    "\n",
    "asf_cube_cf.x.attrs.update({\"grid_mapping\": \"grid_mapping\"})\n",
    "asf_cube_cf.y.attrs.update({\"grid_mapping\": \"grid_mapping\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_updated = pc_subset_ds_cf.cf.add_bounds([\"x\", \"y\"])\n",
    "asf_updated = asf_cube_cf.cf.add_bounds([\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr(asf_updated.cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr(pc_updated.cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to make a `xe.Regridder` obj:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_grid = {\n",
    "    \"x\": pc_updated.x.values,\n",
    "    \"y\": pc_updated.y.values,\n",
    "}\n",
    "target_grid = {\n",
    "    \"x\": asf_updated.x.values,\n",
    "    \"y\": asf_updated.y.values,\n",
    "}\n",
    "regridder = xe.Regridder(pc_updated, asf_updated, method=\"bilinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm missing something about how to make this fully cf complient\n",
    "- is it something to do with SAR backscatter not being recognized as a CF variable? or probably something more simple about coords?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd approach, convert to geographic coords\n",
    "\n",
    "Seems less desirable than keeping things in projected utm? but seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_ll = asf_cube.rio.reproject(\"epsg:4326\")\n",
    "pc_ll = pc_subset_ds.rio.reproject(\"epsg:4326\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make `xesmf.Regridder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_out_ll = xr.Dataset(\n",
    "    {\"lat\": ([\"lat\"], asf_ll.y.data), \"lon\": ([\"lon\"], asf_ll.x.data)}\n",
    ")\n",
    "regridder = xe.Regridder(pc_ll, pc_out_ll, \"bilinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_out_ll = regridder(pc_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_out_ll = pc_out_ll.rio.write_crs(pyproj.CRS.from_epsg(4326))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project back to UTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_out_prj = pc_out_ll.rename({\"lat\": \"y\", \"lon\": \"x\"}).rio.reproject(pc_subset.rio.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_prj = asf_ll.rio.reproject(asf_cube.rio.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_to_db(input_arr: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Convert power values to decibel (dB) scale.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_arr : np.array\n",
    "        Input array containing power values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        Output array with values converted to decibel (dB) scale.\n",
    "    \"\"\"\n",
    "    return 10 * np.log10(np.abs(input_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "power_to_db(pc_out_prj[\"vv\"].mean(dim=\"time\")).plot(cmap=plt.cm.Greys_r, ax=ax[0])\n",
    "power_to_db(asf_prj[\"vv\"].mean(dim=\"time\")).plot(cmap=plt.cm.Greys_r, ax=ax[1])\n",
    "\n",
    "ax[0].set_title(\"PC\")\n",
    "ax[1].set_title(\"ASF\")\n",
    "ax[1].set_ylabel(None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(asf_prj.x.data, pc_out_prj.x.data)\n",
    "np.testing.assert_array_equal(asf_prj.y.data, pc_out_prj.y.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to `xr.interp_like()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another downsampled PC dataset, this time using `xr.interp_like()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_downsample = pc_subset.interp_like(asf_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot both downsampled objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "power_to_db(pc_out_prj[\"vv\"].mean(dim=\"time\")).plot(cmap=plt.cm.Greys_r, ax=ax[0])\n",
    "power_to_db(pc_downsample.sel(band=\"vv\").mean(dim=\"time\")).plot(\n",
    "    cmap=plt.cm.Greys_r, ax=ax[1]\n",
    ")\n",
    "\n",
    "ax[0].set_title(\"xesmf regridded\")\n",
    "ax[1].set_title(\"interp_like() regridded\")\n",
    "ax[1].set_ylabel(None)\n",
    "fig.suptitle(\"Downsampled PC VV backscatter, comparing regridding methods\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the shapes of the two downsampled objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of downsampled object made with xesmf regridding: \\n\", pc_out_prj.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Shape of downsampled object made with xr.interp_like: \\n\",\n",
    "    pc_downsample.to_dataset(dim=\"band\").drop_dims(\"band\").dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The xesmf regridded object a longer x-coordinate. In this case, because the geometries of the input objects were relatively similar, `xr.interp_like()` is an appropriate choice. If you are trying to regrid an object where there is greater dissimilarity between the target and source grids, options like XESMF may be a better choice. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_datacube_book_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
