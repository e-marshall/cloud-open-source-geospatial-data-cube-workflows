{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb81f54f-e4e4-42ab-8dd7-609243a21793",
   "metadata": {},
   "source": [
    "{{title_s1_5}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ae299-26ac-4401-b0ad-bb817e327b6f",
   "metadata": {},
   "source": [
    "So far in this tutorial, we've demonstrated how to read Sentinel-1 RTC imagery from two sources and assemble analysis-ready data cubes with appropriate metadata. Now, we'll perform a comparison of the two datasets. \n",
    "\n",
    "::::{tab-set}\n",
    ":::{tab-item} Dataset comparison\n",
    "\n",
    "While the two datasets are very similar, there are a few key differences:  \n",
    "1) They use different sources images.   \n",
    "    - ASF Sentinel-1 RTC imagery is processed from Single Look Complex ([SLC](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1-algorithms/single-look-complex)) images while Planetary Computer Sentinel-1 RTC imagery is processed from Ground Range Detected ([GRD](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1-algorithms/ground-range-detected)) images. SLC images contain both amplitude and phase information for each pixel. They are in radar coordinates and have not yet been multi-looked. In contrast, GRD images has been detected, multi-looked and projected to ground range.\n",
    "\n",
    "2) They use different digital elevation models (DEMs) for terrain correction.  \n",
    "    - ASF uses the [GLO-30 Copernicus DEM](https://dataspace.copernicus.eu/explore-data/data-collections/copernicus-contributing-missions/collections-description/COP-DEM) while Planetary Computer uses a Planet DEM.  \n",
    "3) The datasets have different pixel spacings. For Planetary Computer, the pixel spacing is 10m in both range and azimuth directions. ASF has the option to produce images with 30 m, 20 m, or 10 m pixel spacaing. The data used in this tutorial is 30 m. Note that there are tradeoffs in processing time and file size with pixel spacing, see more discussion [here](https://hyp3-docs.asf.alaska.edu/guides/rtc_product_guide/#pixel-spacing_1).  \n",
    "4) Each platform uses a different algorithm for RTC processing.\n",
    "5) The ASF dataset comes with an associated layover shadow map for each scene while the Planetary Computer dataset does not.  \n",
    "\n",
    "All of the above information and much more detail about the processing methods for both datasets are available in each dataset's documentation pages:\n",
    "- [ASF Sentinel-1 RTC Product Guide](https://hyp3-docs.asf.alaska.edu/guides/rtc_product_guide/#pixel-spacing_1)  \n",
    "- [Microsoft Planetary Computer Sentinel-1 RTC dataset](https://planetarycomputer.microsoft.com/dataset/sentinel-1-rtc) \n",
    "::: \n",
    "\n",
    ":::{tab-item} Outline\n",
    "\n",
    "(content.Section_A)=\n",
    "**[A. Read and prepare data](#a-read-and-prepare-data)**  \n",
    "- {{a1_s1_nb5}}  \n",
    "\n",
    "(content.Section_B)=\n",
    "**[B. Ensure direct comparison between datasets](#b-ensure-direct-comparison-between-datasets)**\n",
    "- {{b1_s1_nb5}}\n",
    "- {{b2_s1_nb5}}\n",
    "- {{b3_s1_nb5}}\n",
    "\n",
    "(content.Section_C)=\n",
    "**[C. Combine objects](#c-combine-objects)**\n",
    "- {{c1_s1_nb5}}\n",
    "- {{c2_s1_nb5}}\n",
    "\n",
    "(content.Section_D)=\n",
    "**[D. Visualize comparisons](#d-visualize-comparisons)**\n",
    "- {{d1_s1_nb5}}\n",
    "- {{d2_s1_nb5}}\n",
    "\n",
    ":::\n",
    ":::{tab-item} Learning goals\n",
    "\n",
    "## Xarray and python techniques\n",
    "- Conditional selection based on non-dimensional coordinates using `xr.Dataset.where()`\n",
    "- Subsetting datasets based on dimensional coordinates using `xr.DataArray.isin()`\n",
    "- Adding dimensional and non-dimensional coordinates to `xr.Dataset` objects\n",
    "- Xarray plotting methods\n",
    "- Projecting xarray objects to different grids using `xr.interp_like()`\n",
    "\n",
    "## High-level science goals\n",
    "- Comparing and evaluating multiple datasets\n",
    "\n",
    ":::\n",
    "::::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7dfad4-f399-4ad1-b733-1f6eb04ceefc",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%xmode minimal\n",
    "import dask.distributed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import stackstac\n",
    "import xarray as xr\n",
    "import pystac\n",
    "import planetary_computer\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "import s1_tools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c0bba",
   "metadata": {},
   "source": [
    "{{break}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a37accb-b1af-4048-b365-616c48d8ebb5",
   "metadata": {},
   "source": [
    "## A. Read and prepare data\n",
    "\n",
    "At the end of notebook 3, we wrote the analysis-ready ASF Sentinel-1 data cube that had been clipped to a smaller spatial area of interest to disk. We'll read that into memory now to use in this comparison.\n",
    "\n",
    "We used Jupyter cell magic to persist the Planetary Computer data cube created in noteboook 4. Now we can read it into our notebook by adding `-r` to the store magic command used to persist it. Read more about `storemagic` [here](https://ipython.readthedocs.io/en/stable/config/extensions/storemagic.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31904346",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r da\n",
    "pc_cube = da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c4a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_cube = pc_cube.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63bb8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_type = 'full'\n",
    "\n",
    "asf_cube = xr.open_dataset(f'../data/{timeseries_type}_timeseries/intermediate_cubes/s1_asf_clipped_cube.zarr',\n",
    "                           engine='zarr',chunks='auto', decode_coords='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "090d61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube = asf_cube.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b3a6e1",
   "metadata": {},
   "source": [
    "### {{a1_s1_nb5}}\n",
    "\n",
    "First, make sure that both objects are projected to the same CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dade7c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pc_cube.rio.crs == asf_cube.rio.crs, 'CRS of both data cubes are expected to be identical.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343285c9",
   "metadata": {},
   "source": [
    "Let's also check how mising data is handled in both objects. We want missing data to be assigned NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3e4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube['vv'].rio.nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94053f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_cube.sel(band='vv').rio.nodata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec6386",
   "metadata": {},
   "source": [
    "The `pc_cube` array contains nan values, but it doesn't have an encoding specifying what value is used to represent nodata. We can assign a nodata value to the dataset below. See Rioxarray's [Nodata Management documentation](https://corteva.github.io/rioxarray/stable/getting_started/nodata_management.html) for more detail on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c341ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_cube.rio.write_nodata(np.nan, inplace=True)\n",
    "pc_cube.rio.nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2a90545",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isnan(asf_cube.vh.rio.nodata) == np.isnan(pc_cube.sel(band='vh').rio.nodata) == True, 'Expected vh nodata value to be np.nan'\n",
    "assert np.isnan(asf_cube.vv.rio.nodata) == np.isnan(pc_cube.sel(band='vv').rio.nodata) == True, 'Expected vv nodata value to be np.nan'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41736f",
   "metadata": {},
   "source": [
    "## B. Ensure direct comparison between datasets\n",
    "\n",
    "Both objects have temporal dimensions with the same length, so we can be reasonably sure that these two objects have common acquisitions but we can do a few more things to be sure about that. \n",
    "\n",
    "Thanks to all of the metadata wrangling we did in earlier notebooks, we can quickly access variables like acquisition date and time, data take IDs and absolute orbit numbers to verify that the we're working with comparable objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37562bb8",
   "metadata": {},
   "source": [
    "### {{b1_s1_nb5}}\n",
    "\n",
    "If we try to compare orbit numbers right away (eg: `asf_cube['abs_orbit_num'].data == pc_cube['sat:absolute_orbit']`), we will get that they are false. This is because the data in the underlying numpy arrays is currently not of the same type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe897b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(asf_cube['abs_orbit_num'].data.dtype)\n",
    "print(pc_cube['sat:absolute_orbit'].data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705367fb",
   "metadata": {},
   "source": [
    "Convert the absolute orbit array of `asf_cube` to an array of integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c798319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube['abs_orbit_num'] = asf_cube['abs_orbit_num'].astype(int)\n",
    "                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c014e5",
   "metadata": {},
   "source": [
    "Now compare them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube['abs_orbit_num'].data == pc_cube['sat:absolute_orbit'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2ddf9",
   "metadata": {},
   "source": [
    "### {{b2_s1_nb5}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e521d",
   "metadata": {},
   "source": [
    "The PC dataset has a higher spatial resolution than the ASF dataset, which you can see in the sizes of the x and y dimensions of the dataset. The ASF dataset masks out more pixels due to shadow than the PC dataset. To explore whether or not this is the cause of the observed backscatter offset between the two, we need to mask out the pixels in the PC dataset that are masked in the ASF dataset. \n",
    "\n",
    "In order to do this, first we must downsample the PC dataset to match the spatial resolution of the ASF dataset. There are multiple xarray methods that could be used but here we will use the `xr.interp_like()` method because we would like the PC x and y dimensions to match the ASF dimension exactly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0909ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube = asf_cube.rename({\"acq_date\": \"time\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcc9996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_da = asf_cube.to_dataarray(dim='band')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63bff3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_downsample = pc_cube.interp_like(asf_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecac89a5",
   "metadata": {},
   "source": [
    "### {{b3_s1_nb5}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63ee3ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_mask = xr.where(asf_da.notnull(), pc_downsample, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af65216",
   "metadata": {},
   "source": [
    "## C. Combine objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87132a0",
   "metadata": {},
   "source": [
    "### {{c1_s1_nb5}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33b488fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_da = asf_da.expand_dims('source')\n",
    "pc_mask = pc_mask.expand_dims('source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e6b037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_da['source'] = ('source', ['asf'])\n",
    "pc_mask['source'] = ('source', ['pc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073f8490",
   "metadata": {},
   "source": [
    "### {{c2_s1_nb5}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "023d2e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_obj = xr.combine_by_coords([asf_da, pc_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae6d44",
   "metadata": {},
   "source": [
    "## D. Visualize comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24286470",
   "metadata": {},
   "source": [
    "### {{d1_s1_nb5}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2bd67",
   "metadata": {},
   "source": [
    "Look at VV backscatter first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_fg = s1_tools.power_to_db(comparison_obj.sel(band='vv').isel(time=1)).plot(col='source', \n",
    "                                                cmap=plt.cm.Greys_r, cbar_kwargs=({'label':'dB'}))\n",
    "vv_fg.fig.suptitle('Comparing VV backscatter from ASF and PC datasets')\n",
    "vv_fg.fig.supxlabel('X coordinate of projection (m)')\n",
    "vv_fg.fig.supylabel('Y coordinate of projection (m)')\n",
    "vv_fg.fig.set_figheight(7)\n",
    "vv_fg.fig.set_figwidth(12)\n",
    "\n",
    "for i in range(len(vv_fg.axs[0])):\n",
    "    \n",
    "    vv_fg.axs[0][i].set_xlabel(None)\n",
    "    vv_fg.axs[0][i].set_ylabel(None)\n",
    "vv_fg.axs[0][0].set_title('ASF')\n",
    "vv_fg.axs[0][1].set_title('PC')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8db463e",
   "metadata": {},
   "source": [
    "Then VH:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1249ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vh_fg = s1_tools.power_to_db(comparison_obj.sel(band='vh').isel(time=1)).plot(col='source', \n",
    "                                                cmap=plt.cm.Greys_r, cbar_kwargs=({'label':'dB'}))\n",
    "vh_fg.fig.suptitle('Comparing VH backscatter from ASF and PC datasets')\n",
    "vh_fg.fig.supxlabel('X coordinate of projection (m)')\n",
    "vh_fg.fig.supylabel('Y coordinate of projection (m)')\n",
    "vh_fg.fig.set_figheight(7)\n",
    "vh_fg.fig.set_figwidth(12)\n",
    "for i in range(len(vh_fg.axs[0])):\n",
    "    \n",
    "    vh_fg.axs[0][i].set_xlabel(None)\n",
    "    vh_fg.axs[0][i].set_ylabel(None)\n",
    "vh_fg.axs[0][0].set_title('ASF')\n",
    "vh_fg.axs[0][1].set_title('PC')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f931b4",
   "metadata": {},
   "source": [
    "### {{d2_s1_nb5}}\n",
    "\n",
    "Instead of computing mean backscatter values along the time dimension, reduce along the spatial dimensions (x and y) to see backscatter variability over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8104ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, figsize=(14,8), layout='constrained')\n",
    "s1_tools.power_to_db(comparison_obj.sel(source='asf',band='vv').mean(dim=['x','y'])).plot.scatter(x='time', ax=ax[0], label='asf',\n",
    "                                                                                                  c='b', alpha=0.75)\n",
    "s1_tools.power_to_db(comparison_obj.sel(source='pc',band='vv').mean(dim=['x','y'])).plot.scatter(x='time', ax=ax[0], label='pc',\n",
    "                                                                                                 c='r',alpha=0.75)\n",
    "\n",
    "s1_tools.power_to_db(comparison_obj.sel(source='asf',band='vh').mean(dim=['x','y'])).plot.scatter(x='time', ax=ax[1], label='asf',\n",
    "                                                                                                  c='b',alpha=0.75)\n",
    "s1_tools.power_to_db(comparison_obj.sel(source='pc',band='vh').mean(dim=['x','y'])).plot.scatter(x='time', ax=ax[1], label='pc',\n",
    "                                                                                                 c='r',alpha=0.75)\n",
    "ax[0].legend(loc='lower right', bbox_to_anchor=([1,-.25,0,0]))\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    ax[i].set_xlabel(None)\n",
    "    ax[i].set_ylabel('dB');\n",
    "\n",
    "ax[0].set_title('VV')\n",
    "ax[1].set_title('VH')\n",
    "\n",
    "fig.supxlabel('Time')\n",
    "#fig.supylabel('dB')\n",
    "fig.suptitle('Comparing mean VV and VH backscatter over time from PC (red) and ASF (blue) datasets', fontsize=14, y=1.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7996fd04",
   "metadata": {},
   "source": [
    "{{conclusion}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_datacube_book_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
