{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce46eaf7-1d78-4afe-859f-661c58ffbee1",
   "metadata": {},
   "source": [
    "# 3. Read and inspect Sentinel-1 RTC imagery processed by Microsoft Planetary Computer \n",
    "\n",
    "This book will demonstrate how to access radiometrically terrain corrected Sentinel-1 imagery from Microsoft Planetary Computer using `stackstac`. STAC stands for spatio-temporal asset catalog, it is a common framework to describe geospatial information and a way for data providers, developers and users to work and communicate efficiently. You can read more about STAC [here](https://stacspec.org/en) and checkout more useful tutorials for working with STAC data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b415a7aa-319f-4ca5-86fe-8e7588652b59",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "**Xarray and python techniques:** <br>\n",
    "- Introduction to working with STAC data\n",
    "- Using `pystac` to query cloud-hosted datasets, observe metadata\n",
    "- Using `stackstac` to read cloud-hosted data as xarray objects\n",
    "- Using `xarray` to manipulate and organize Sentinel-1 SAR data\n",
    "- Performing grouping and reductions on `xarrray` objects\n",
    "- Visualizing `xarray` objects using `FacetGrid`\n",
    "\n",
    "**High-level science goals:**<br>\n",
    "- Querying large cloud-hosted dataset\n",
    "- Accessing cloud-hosted data stored as COGs (cloud-optimized GeoTIFFs)\n",
    "- Extracting and organizing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bb298-9f22-47e1-afba-af9a7ef77978",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%xmode minimal\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import planetary_computer\n",
    "import pystac\n",
    "import rich.table\n",
    "import xarray as xr\n",
    "import stackstac\n",
    "\n",
    "from IPython.display import Image\n",
    "from pystac_client import Client\n",
    "\n",
    "import s1_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8907c79c-b4fe-4e38-a858-60b6d731eb46",
   "metadata": {},
   "source": [
    "We will use the `pystac_client` package to interact with and query the Microsoft Planetary Computer Sentinel-1 RTC dataset. In the cell below, we will create an object called `catalog` by calling the `.open()` method of the `Client` class. This is establishing a connection with the hosted data at the url provided. Explore the catalog object. You "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbcbe6-62ca-4ccd-9162-d412e18ee09c",
   "metadata": {},
   "source": [
    "## STAC items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065310e4-a5e1-4997-9a44-ef5936f9ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca010bf-ef52-4c75-8d42-88667f0af875",
   "metadata": {},
   "source": [
    "Now we will define some parameters to help us query the data catalog for the specific collection, time range and geographic area of interest. \n",
    "The function `points2coords()` just helps us to format coordinates for areas of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd26316-b0cf-4ae8-a839-1cf619714e3f",
   "metadata": {},
   "source": [
    "In the cell below we specify the time range we're interested in as well as the geographic area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f3adbc-296e-45de-8fcd-e5e2b8860f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = \"2021-01-01/2022-08-01\"\n",
    "bbox = [88.214935, 27.92767, 88.302, 28.034]\n",
    "\n",
    "bbox_coords = s1_tools.points2coords(bbox)\n",
    "bbox_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc50291-dad1-41bd-b5ff-de6dd69adc4e",
   "metadata": {},
   "source": [
    "Now we will search the catalog for entries that match our criteria for collection (Sentinel-1 RTC), bbox (our AOI) and datetime (our specified time range):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83d0c9-a493-415c-bc52-419a51fc3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = catalog.search(collections=[\"sentinel-1-rtc\"], bbox=bbox, datetime=time_range)\n",
    "items = search.item_collection()\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a6ba5-280f-459c-bf4b-1cb2516ef760",
   "metadata": {},
   "source": [
    "We've created a few more instances of `pystac_client` classes. Check out the object types below to better familiarize yourself with the pystac package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12a334-216c-4eaf-9bdb-f106be58d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(catalog))\n",
    "print(type(search))\n",
    "print(type(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450d2505-8797-456a-bd8a-97d7357ab785",
   "metadata": {},
   "source": [
    "You can see that `items` is an instance of the class `ItemCollection`, and we can explore it via the embedded html interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063d9fb-dd6f-4ae8-89c3-eaab540c2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4905f-4661-4473-87ec-c865fd29f97f",
   "metadata": {},
   "source": [
    "To make it easier to work with, we can convert  the `items` object to a dictionary, and from there, convert it to a `geopandas.GeoDataFrame`. You can see that the metadata from within each `item` of the `ItemCollection` object is present in the `GeoDataFrame` but its easier to scan and organize this way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e18e6e6-3487-43d3-b50d-4afd3c1d562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.GeoDataFrame.from_features(items.to_dict(), crs=\"epsg:4326\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17ce44-2675-4ac0-97e7-e1c851249da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e53dff3-9782-4f2e-8a2a-a5806693acb9",
   "metadata": {},
   "source": [
    "Now we want to check out a rendered preview of an individual item from the `ItemCollection` object. We do this by calling the `assets` accessor, and supplying the HREF of the rendered preview key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee9bdf-8c29-4130-a06e-cdf8be60f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=items[0].assets[\"rendered_preview\"].href)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e193a-99b6-4deb-99e9-0988920b36a2",
   "metadata": {},
   "source": [
    "We can construct a table with metadata for a single scene (ie. a single element of the list `items`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6715f677-c87f-47fa-94cb-9fb7837174cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = rich.table.Table(\"key\", \"value\")\n",
    "for k, v in sorted(items[0].properties.items()):\n",
    "    table.add_row(k, str(v))\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6bc1bf-5b49-4533-aea7-2862b812985c",
   "metadata": {},
   "source": [
    "We can also explore the object metadata outside of the table. Try typing `.assets`, `.links`, `.STAC_extensions` and `.properties` onto the term below. \n",
    "You can query the object programmatically for the same metadata stored in the table using dictionary syntax on the `properties` accessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a354c-f6e5-46be-86ef-aca0273016e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "items[0]\n",
    "# items[0].assets\n",
    "# items[0].links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e41424b-3fa8-4a56-9c34-0199b49cc4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "items[0].properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de05888e-e358-418f-8e4e-baf45b5eb0fe",
   "metadata": {},
   "source": [
    "Now that we'e explored the items that fit our query of the dataset and seen the metadata, let's read the data in using xarray. \n",
    "\n",
    "We will now use `dask.distributed` to manage our tasks. Confusingly, we will use the dask.distributed class `Client` to interact with the cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ba6ab-1fa5-4933-bf35-acb54dda18e0",
   "metadata": {},
   "source": [
    "## Reading data using xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff0af4b",
   "metadata": {},
   "source": [
    "## TODO \n",
    "if keep this here, explain dask distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98cb544-66d0-4e3a-8374-a066fccc5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(processes=False)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add748dd-c81d-4e49-bfcd-78125a6d9a0d",
   "metadata": {},
   "source": [
    "The `client.dashboard_link` points to a dask dashboard for the client we've just instantiated. \n",
    "\n",
    "Now that we have queried the data that is available from Microsoft Planetary Computer and inspected the metadata using `pystac`, we will use `stackstac` to read the data into our notebook as an xarray object. Calling `stackstac.stack()` produces a lazy `xarray.DataArray` with dask integration out of a STAC `collection` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c95433-ad4a-4e18-93eb-108324bdd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66c64ed-c149-418c-902d-8641f9075eac",
   "metadata": {},
   "source": [
    "In the code cell below, you can see that we pass the object `items`, a `pystac.ItemCollection` to the `stackstac.stack()` method. The wrapper `planetary_computer.sign()` uses Planetary Computer subscription key credentials to access the data. `stackstac` passes the metadata from the STAC collection into the xarray object as coordinates allowing you to further organize and manipulate the object to fit your purposes. `stackstac` can also read the data in according to parameters passed during the `stack()` call. In the code cell below we pass parameters for bounding box and coordinate reference system. To specify the resolution as something other than the resolution at which its stored, pass a `resolution = ` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ac33f88-f70d-454d-a598-bc1939409d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = stackstac.stack(planetary_computer.sign(items), bounds_latlon=bbox, epsg=32645)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e1d7ce-e994-4709-8ed5-f3d131a12bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b6cb3-882b-4c58-84bc-1be626c2daed",
   "metadata": {},
   "source": [
    "### Retrieve source granule ID\n",
    "\n",
    "It will be useful to have the granule ID for the original SAR acquisition and GRD file used to generate the RTC image. The following code demonstrates retrieving the source granule ID from the STAC metadata and adding it as a coordinate variable to the xarray object  containing the RTC imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a906e82-068a-49ac-9853-ef75bbeb0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_item = pystac.read_file(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-1-rtc/items/S1A_IW_GRDH_1SDV_20210602T120544_20210602T120609_038161_0480FD_rtc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f05d3d05-b581-49d0-93fa-b1d9614d03df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_source_granule_pc(rtc_id):\n",
    "    base_url = \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-1-rtc/items/\"\n",
    "    full_url = base_url + str(rtc_id)\n",
    "    stac_item = pystac.read_file(full_url)\n",
    "    source_granule = stac_item.links[5].target[-62:]\n",
    "    return source_granule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd862461-6efc-47da-8652-3ad595897197",
   "metadata": {},
   "outputs": [],
   "source": [
    "granule_ls = [\n",
    "    extract_source_granule_pc(da.isel(time=t).id.values) for t in range(len(da.time))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "486e37a2-337f-4201-8878-0f65b1d39d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_granule_coord_pc(granule_ls):\n",
    "    \"\"\"this fn takes a list of granule IDs, extracts acq date for each granule, organizes this as an array that can be assigned as a coord to an xr obj\"\"\"\n",
    "\n",
    "    acq_date = [pd.to_datetime(granule[17:25]) for granule in granule_ls]\n",
    "\n",
    "    granule_da = xr.DataArray(\n",
    "        data=granule_ls,\n",
    "        dims=[\"time\"],\n",
    "        coords={\"time\": acq_date},\n",
    "        attrs={\n",
    "            \"description\": \"source granule ID S1 GRD files used to process PC RTC images, extracted from STAC metadata\"\n",
    "        },\n",
    "        name=\"granule_id\",\n",
    "    )\n",
    "\n",
    "    return granule_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1058d25f-5325-469d-ae7b-2ed46aa89d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "granule_coord = make_granule_coord_pc(granule_ls)\n",
    "granule_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a8d89-bb05-4d2a-8a28-4f7f36ce0bd1",
   "metadata": {},
   "source": [
    "The `granule_coord` object is a 1-dimensional xarray.DataArray containing the source granule IDs for the original GRD files. The values of the `time` coordinate align with the time coordinate of the data object `pc`, allowing us to use the [`xarray.combine_by_coords()`](https://docs.xarray.dev/en/stable/generated/xarray.combine_by_coords.html) function to merge the two into one object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae93b699-71b8-4c69-9c56-dd19742b861c",
   "metadata": {},
   "source": [
    "First, check the dates between the two coordinates are the same (they should be):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da724f-fc6a-41c6-8201-47ea23c5f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in range(len(list(da.time)))[:5]:\n",
    "    print(list(da.time.values)[element])\n",
    "    print(list(granule_coord.time.values)[element])\n",
    "    print(\"\")\n",
    "print(len(da.time))\n",
    "print(len(granule_coord.time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c6eeac-8ef1-4304-9c81-0d5034d57b20",
   "metadata": {},
   "source": [
    "Now, assign granule id as a **non-dimensional coordinate** of the xarray dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4f062f4-528a-424c-80fb-dab6a9556bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.coords[\"granule_id\"] = (\"time\", granule_coord.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e9b2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dac65bad-342d-4df4-b6ee-5c0bd1d70651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename for when we store it to use in the comparison notebook3\n",
    "# da_pc = da\n",
    "# da_pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059c3f79-6393-4466-a10e-8aec996bd82e",
   "metadata": {},
   "source": [
    "Great, now we have a data cube of Sentinel-1 RTC backscatter imagery with `x`,`y` and `time` dimensions. Take a look at the coordinates and you can see that there is much more information that we can use to query and filter the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f5ae2a-cbbb-4603-b6bb-b7b2092ba6d6",
   "metadata": {},
   "source": [
    "Let's do a little bit of looking around. We'll define a function to convert the backscatter pixel values from power to dB scale but we won't use it yet. This transformation applies a logarithmic scale to the data which makes visualization easier but we do not want to run any summary statistics on the dB data as it will be distorted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08429cf-c8bf-4963-98eb-00047ef8b703",
   "metadata": {},
   "source": [
    "What if we only wanted to look at imagery from the `VV` band? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfc393ca-9dae-4a96-95fe-83b023a67806",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_vv = da.sel(band=\"vv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c43a85a-4357-4ccf-a4f2-973f197a97d2",
   "metadata": {},
   "source": [
    "We can do the same for `VH`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94c9ea82-82b1-4306-9f85-9e8a351152e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_vh = da.sel(band=\"vh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868197fe-002d-491a-8503-32391c89b009",
   "metadata": {},
   "source": [
    "Next, what if we wanted to look only at imagery taken during `ascending` or `descending` passes of the satellite? `band` is a dimensional coordinate, so we could use xarray's `.sel()` method, but orbital direction is a non-dimensional coordinate so we need to approach it a bit differently: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e59b1-1f7d-4bf5-bec6-6c6ba7bac205",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_asc = da.where(da[\"sat:orbit_state\"] == \"ascending\", drop=True)\n",
    "da_desc = da.where(da[\"sat:orbit_state\"] == \"descending\", drop=True)\n",
    "da_asc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da726ad2-2949-46e5-be7f-cc2ff9061280",
   "metadata": {},
   "source": [
    "You can see that there are 69 time steps from the Ascending orbital pass and that all of the same dimensions and coordinates still exist, so you can subset for just the `VV` data from the ascending passes, or other variables you may be interested in.\n",
    "\n",
    "Let's take a look at the two polarizations side-by-side. Below, we'll plot the `VV` and `VH` polarizations from the same date next to each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1e353-2375-409e-9418-448e83bacaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(16, 8))\n",
    "s1_tools.power_to_db(da_asc.sel(band=\"vv\").isel(time=10)).plot(\n",
    "    cmap=plt.cm.Greys_r, ax=axs[0]\n",
    ")\n",
    "s1_tools.power_to_db(da_asc.sel(band=\"vh\").isel(time=10)).plot(\n",
    "    cmap=plt.cm.Greys_r, ax=axs[1]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd9e8c0-387d-4e7f-97f9-4d49a33a0c83",
   "metadata": {},
   "source": [
    "It looks like there is some interesting variability between the two images. What if we wanted to see how these differences persist over time?\n",
    "\n",
    "Let's perform a reduction along the `x` and `y` dimensions so that we can get a better idea of this data over time rather than a snapshot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f16b5e-b502-4549-8fd6-a11b11e2e770",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_asc.sel(band=\"vv\").mean(dim=[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f8f26-0dd2-47e4-93e9-b95c5dafe24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "ax.set_title(\n",
    "    \"Mean backscatter from ASCENDING passes for VH band (red) and VV band (blue) over time\"\n",
    ")\n",
    "s1_tools.power_to_db(da_asc.sel(band=\"vv\").mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=ax, linestyle=\"None\", marker=\"o\", color=\"red\"\n",
    ")\n",
    "s1_tools.power_to_db(da_asc.sel(band=\"vh\").mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=ax, linestyle=\"None\", marker=\"o\", color=\"blue\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7362a267-643d-48d8-a5bf-8e386527f436",
   "metadata": {},
   "source": [
    "Interesting! It looks like there is more variability in the VH band than the VV band. Over the year, there is about 4 dB variability in the VV band but over twice as much in the VH band. Chapter 2 of the [SAR handbook](https://gis1.servirglobal.net/TrainingMaterials/SAR/Chp2Content.pdf) contains information about how polarization impacts radar returns. \n",
    "The above plots are looking only at the ascending passes. Let's take a look at all of the time steps (ascending + descending). Any effects based on the different viewing geometries of the ascending and descending passes should have been removed during the radiometric terrain correction step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6a399-5537-42c7-9df3-f366fdfa55a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "ax.set_title(\"Mean backscatter for VH band (red) and VV band (blue) over time\")\n",
    "s1_tools.power_to_db(da.sel(band=\"vv\").mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=ax, linestyle=\"None\", marker=\"o\", color=\"red\"\n",
    ")\n",
    "s1_tools.power_to_db(da.sel(band=\"vh\").mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=ax, linestyle=\"None\", marker=\"o\", color=\"blue\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5178ff37-5984-4e64-beaf-03f635db087a",
   "metadata": {},
   "source": [
    "Next, let's take a look at how backscatter values vary seasonally. To do this we will use xarray's [groupby()]() and [.facetgrid]() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "125e874a-1952-4f3c-86b7-cf194f02409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_gb = da.groupby(da.time.dt.season).mean()\n",
    "# add the attrs back to the season groupby object\n",
    "seasons_gb.attrs = da.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e64f65-4360-48bc-acba-30cb28ce0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b63f7-20b4-4a82-b99f-ed50d3363d34",
   "metadata": {},
   "source": [
    "Use the seasons groupby object and specify the `season` dimension in the `Facetgrid` call to automatically plot mean backscatter for each season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d218b78-556c-41ad-9484-6ca502e5c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_vv = s1_tools.power_to_db(seasons_gb.sel(band=\"vv\")).plot(\n",
    "    col=\"season\", cmap=plt.cm.Greys_r\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d37e69-a8ee-40a5-9c6e-5a05ecf180c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_vh = s1_tools.power_to_db(seasons_gb.sel(band=\"vh\")).plot(\n",
    "    col=\"season\", cmap=plt.cm.Greys_r\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d329a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pc = da.to_dataset(dim=\"band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "727276ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pc = ds_pc.drop_dims(\"band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3919112",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pc = ds_pc.drop(\"sar:polarizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f710a79a",
   "metadata": {},
   "source": [
    "Can i avoid writing this to file/storing it? Maybe instead write quick script to create it in next notebooks  ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a045f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pc = ds_pc.drop(\"raster:bands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0601e6b1",
   "metadata": {},
   "source": [
    "We will see that we run into some errors trying to write this object to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e349fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, compute\n",
    "#ds_pc = ds_pc.compute()\n",
    "# Try to write to zarr\n",
    "#ds_pc.to_zarr(\"../data/tutorial2/s1_pc_cube.zarr\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b460cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pc.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3218307",
   "metadata": {},
   "source": [
    "The issue seems to be related to one of the `ds_pc` attributes: `RasterSpec`. RasterSpec is an object from the `stackstac` library, which we used to read STAC assets into memory as an Xarray `DataArray` object. It holds a dict-like object that has information about the coordinate reference system, spatial extent and spatial resolution of the object. Let's change it to an object that is JSON serializable so that we can write this object to disk with Zarr without losing any of this metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33cd5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rasterspec = ds_pc.attrs[\"spec\"]\n",
    "\n",
    "#spec_dict = {\n",
    "#    \"epsg\": rasterspec.epsg,\n",
    "#    \"bounds\": rasterspec.bounds,\n",
    "#    \"resolutions_xy\": rasterspec.resolutions_xy,\n",
    "#}\n",
    "#ds_pc.attrs.pop(\"spec\")\n",
    "#ds_pc.attrs[\"spec_dict\"] = spec_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84eec83",
   "metadata": {},
   "source": [
    "Great, now we should be able to write this object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b93fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_pc.to_zarr(\"../data/tutorial2/s1_pc_cube.zarr\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c6bb9-f9fe-42b9-bfd6-2e715c413c91",
   "metadata": {},
   "source": [
    "## Wrap up\n",
    "\n",
    "This notebook demonstrated how to access cloud-hosted data from Microsoft Planetary Computer, some basic dataset organization and preliminary exploration and visualization. The following notebook will compare the Planetary Computer dataset to the ASF dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83247a5a-773c-4905-9bab-457ebad56594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_datacube_book_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
