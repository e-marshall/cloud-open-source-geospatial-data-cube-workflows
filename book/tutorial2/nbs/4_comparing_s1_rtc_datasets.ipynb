{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb81f54f-e4e4-42ab-8dd7-609243a21793",
   "metadata": {},
   "source": [
    "# 1. Comparing Sentinel-1 RTC datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ae299-26ac-4401-b0ad-bb817e327b6f",
   "metadata": {},
   "source": [
    "Now that we have constructed and organized data cubes for both the ASF and Planetary Computer datasets, it would be useful and informative to compare the two. This notebook will demonstrate steps to ensure a direct comparison between the two datasets as well as use of xarray plotting tools for a preliminary visual comparison.\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "**Xarray and python techniques:**\n",
    "- Conditional selection based on non-dimensional coordinates using `xr.Dataset.where()`\n",
    "- Subsetting datasets based on dimensional coordinates using `xr.DataArray.isin()`\n",
    "- Adding dimensional and non-dimensional coordinates to `xr.Dataset` objects\n",
    "- Xarray plotting methods\n",
    "- Projecting xarray objects to different grids using `xr.interp_like()`\n",
    "\n",
    "**High-level science goals**\n",
    "- Comparing and evaluating multiple datasets\n",
    "- Setting up multiple datasets for direct comparisons\n",
    "- Handling differences in spatial resolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7dfad4-f399-4ad1-b733-1f6eb04ceefc",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%xmode minimal\n",
    "import dask.distributed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import stackstac\n",
    "import xarray as xr\n",
    "import pystac\n",
    "import planetary_computer\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "import s1_tools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922bf07-a6c9-4fb2-92f5-5bf76c9e9d64",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "While the datasets we will be comparing in this notebook are quite similar, they contain important differences related to how they were processed. The product description pages for both datasets contain important information for understanding how they are generated.\n",
    "\n",
    "### Source data\n",
    "One important difference is the source data used to generate the RTC images. ASF uses the Single Look Complex ([SLC](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1-algorithms/single-look-complex)) images that contains both amplitude and phase information for each pixel, is in radar coordinates and has not yet been multi-looked. The Microsoft Planetary Computer RTC imagery is generate from ground range detected images (GRD). [GRD](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1-algorithms/ground-range-detected) data has been detected, multi-looked and projected to ground range.\n",
    "\n",
    "### DEM\n",
    "A digital elevation model (DEM) is an important input parameter for RTC processing. ASF RTC processing uses the Copernicus DEM with 30 m resolution. Planetary Computer uses higher resolution DEMs. One effect of the use of different DEMs during RTC processing is the different spatial resolutions of the RTC products: **Planetary Computer RTC imagery has a spatial resolution of 10 meters while ASF RTC imagery has a spatial resolution of 30 meters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a37accb-b1af-4048-b365-616c48d8ebb5",
   "metadata": {},
   "source": [
    "### Read prepared data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc197b16",
   "metadata": {},
   "source": [
    "The PC data cube is a bit too large (~ 1GB). rather than write it to disk like the other examples, maybe just recreate it in this nb? or go back to using cell magic to store it? if recreate it here, wrap in script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31904346",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = \"2021-01-01/2022-08-01\"\n",
    "bbox = [88.214935, 27.92767, 88.302, 28.034]\n",
    "epsg = 32645\n",
    "\n",
    "ds_pc = s1_tools.S1PC_DataCube(time_range, bbox, epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68299f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "\n",
    "catalog = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "time_range = \"2021-01-01/2022-08-01\"\n",
    "bbox = [88.214935, 27.92767, 88.302, 28.034]\n",
    "\n",
    "bbox_coords = s1_tools.points2coords(bbox)\n",
    "search = catalog.search(collections=[\"sentinel-1-rtc\"], bbox=bbox, datetime=time_range)\n",
    "items = search.item_collection()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "dask_client = Client(processes=False)\n",
    "print(dask_client.dashboard_link)\n",
    "\n",
    "da = stackstac.stack(planetary_computer.sign(items), bounds_latlon=bbox, epsg=32645)\n",
    "\n",
    "stac_item = pystac.read_file(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-1-rtc/items/S1A_IW_GRDH_1SDV_20210602T120544_20210602T120609_038161_0480FD_rtc\"\n",
    ")\n",
    "\n",
    "def extract_source_granule_pc(rtc_id):\n",
    "    base_url = \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/sentinel-1-rtc/items/\"\n",
    "    full_url = base_url + str(rtc_id)\n",
    "    stac_item = pystac.read_file(full_url)\n",
    "    source_granule = stac_item.links[5].target[-62:]\n",
    "    return source_granule\n",
    "\n",
    "granule_ls = [\n",
    "    extract_source_granule_pc(da.isel(time=t).id.values) for t in range(len(da.time))\n",
    "]\n",
    "def make_granule_coord_pc(granule_ls):\n",
    "    \"\"\"this fn takes a list of granule IDs, extracts acq date for each granule, organizes this as an array that can be assigned as a coord to an xr obj\"\"\"\n",
    "\n",
    "    acq_date = [pd.to_datetime(granule[17:25]) for granule in granule_ls]\n",
    "\n",
    "    granule_da = xr.DataArray(\n",
    "        data=granule_ls,\n",
    "        dims=[\"time\"],\n",
    "        coords={\"time\": acq_date},\n",
    "        attrs={\n",
    "            \"description\": \"source granule ID S1 GRD files used to process PC RTC images, extracted from STAC metadata\"\n",
    "        },\n",
    "        name=\"granule_id\",\n",
    "    )\n",
    "\n",
    "    return granule_da\n",
    "\n",
    "granule_coord = make_granule_coord_pc(granule_ls)\n",
    "\n",
    "da.coords[\"granule_id\"] = (\"time\", granule_coord.data)\n",
    "\n",
    "ds_pc = da.to_dataset(dim=\"band\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43dbf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_cube = ds_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd90cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pc_cube = xr.open_dataset(\"../data/tutorial2/s1_pc_cube.zarr\", engine=\"zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff5756bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube = xr.open_dataset(\"../data/tutorial2/s1_asf_cube_updated.zarr\", engine=\"zarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aefa137-d59e-400d-ae70-673afa6e56aa",
   "metadata": {},
   "source": [
    "Read in the ASF dataset, which we named `vrt_full` in the earlier notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9a2ec-1bfd-4f48-af25-02549a2499ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c3344-ec97-4ebb-bd46-e6c1bcda60f3",
   "metadata": {},
   "source": [
    "Before we go further, the nodata value for the ASF dataset is currently zero. Change all zero values to NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308ba415-41ac-4373-9273-8e6c632c3c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube = asf_cube.where(asf_cube.vv != 0.0, np.nan, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9265030-147d-4beb-ab47-b48c7760fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315bbae7-273d-4d78-8a26-1a44e2e88f4e",
   "metadata": {},
   "source": [
    "## Extract common data take ID from granule IDs\n",
    "\n",
    "We want to ensure that we are performing a direct comparison of the ASF and PC datasets. To do this, we would like to use the acquisition ID that is stored in the source granule name (published by ESA). In the setup notebooks we attached the entire granule IDs of the SLC images to the ASF dataset and the GRD images to the PC dataset. In the ASF data inspection notebook, we attached data take id as a non-dimensional coordinate. Now we will do the same for the Planetary Computer dataset, extracting just the 6-digit acquisition ID from the granule ID and using this for a scene-by-scene comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6bf163f-e452-49fb-8c61-cf6999d43a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_take_pc = [\n",
    "    str(pc_cube.isel(time=t).granule_id.values)[56:] for t in range(len(pc_cube.time))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a618602-c029-4c9b-9369-81ce63c48c92",
   "metadata": {},
   "source": [
    "Assign `data_take_id` as a non-dimensional coordinate. Rather than use the `xr.assign_coords()` function, we are adding the object by specifying a tuple with the form ('coord_name', coord_data, attrs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "752b5628-79bc-4d7d-9672-1f1dd9c5f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_cube.coords[\"data_take_id\"] = (\"time\", data_take_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92521df-c3b2-44a3-af41-bbffe6f623ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ae867-c31a-45fb-966e-c973fd745107",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce43501-1c4e-4838-b2ed-ba57ed9a5008",
   "metadata": {},
   "source": [
    "### Subset to only common data takes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49d742-a17a-4665-8387-a86a83bfef4d",
   "metadata": {},
   "source": [
    "Now we have data take ID coordinates for both datasets. We want to find the common data take IDs between the two datasets. To do this, I extract a list of the acquisition IDs (`data_take_id`) for both datasets and then find the intersection of the two lists (the list object `common_data_takes`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1ed5e02-58a0-46b0-93d2-c23d9f9c6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data_take_ls = list(pc_cube.data_take_id.values)\n",
    "asf_data_take_ls = list(asf_cube.data_take_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb7eab-8f0e-4b42-89f7-590fd58f3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_data_takes = list(set(pc_data_take_ls) & set(asf_data_take_ls))\n",
    "len(common_data_takes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6f9fe-5ccb-4b8e-b3b9-c16012fcbcfc",
   "metadata": {},
   "source": [
    "It looks like there are 83 RTC images that are generated from common acquisitions between the two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f2ec4a-e4a6-4355-9aab-a42b72398ebc",
   "metadata": {},
   "source": [
    "We'd like to subset the ASF and the PC datasets to only the common acquisitions. The xarray `.isin()` method is very useful for this type of selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e12024b-c576-411e-9812-9e527dc8b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_condition_asf = asf_cube.data_take_id.isin(common_data_takes)\n",
    "\n",
    "subset_condition_pc = pc_cube.data_take_id.isin(common_data_takes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a30060-b379-45af-8491-01e31f530923",
   "metadata": {},
   "source": [
    "Next, we want to select the elements along the `acq_ate` (and `time`) dimensions where `data_take_id` satisfies the requirement of being in the `common_data_takes` list. I found this stack overflow answer useful for this step: [https://stackoverflow.com/questions/70777676/xarray-select-dataarray-according-to-an-non-dimension-coordinate](https://stackoverflow.com/questions/70777676/xarray-select-dataarray-according-to-an-non-dimension-coordinate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19328af2-9b15-457a-9044-6676e1d53f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_subset = asf_cube.sel(acq_date=asf_cube.data_take_id.isin(common_data_takes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e080ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_subset.acq_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37656475-f179-40b2-a276-714cefd980cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset = pc_cube.sel(time=pc_cube.data_take_id.isin(common_data_takes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68524887",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset[\"vv\"].encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "394fd1f1-ef16-42f0-a8d1-358262985edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset = pc_subset.chunk({\"time\": 18, \"y\": 193, \"x\": 111})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3222b2-faac-45e6-9246-95ec65384f2f",
   "metadata": {},
   "source": [
    "## Visual comparison\n",
    "\n",
    "Let's perform some preliminary visual comparisons of the datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27b353-9f28-4a77-be37-29dbc2a64768",
   "metadata": {},
   "source": [
    "#### Individual time steps\n",
    "\n",
    "Use `asf_bc_sidebyside()` to compare snapshot views of backscatter at individual time steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0ceea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e422c57-c174-4cef-8132-960057b22cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_tools.asf_pc_sidebyside(asf_subset, pc_subset, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7dce10-da7c-4714-a938-846a7ea1b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_tools.asf_pc_sidebyside(asf_subset, pc_subset, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47321415-0868-4e48-a1e2-61022eb82fa7",
   "metadata": {},
   "source": [
    "### Average backscatter over time\n",
    "\n",
    "Now we will look at the backscatter mean along the time dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c98884b-5910-4387-897b-aabc60925afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "s1_tools.power_to_db(asf_subset.vv.mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=ax, color=\"blue\", linestyle=\"None\", marker=\"o\", markersize=5, label=\"ASF\"\n",
    ")\n",
    "s1_tools.power_to_db(pc_subset.vv.mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=ax, color=\"red\", linestyle=\"None\", marker=\"o\", markersize=5, label=\"PC\"\n",
    ")\n",
    "fig.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f329a8-b87b-4cf4-a4bc-f938c7456d7a",
   "metadata": {},
   "source": [
    "## Handling spatial resolution differences\n",
    "\n",
    "The PC dataset has a higher spatial resolution than the ASF dataset, which you can see in the sizes of the x and y dimensions of the dataset. The ASF dataset masks out more pixels due to shadow than the PC dataset. To explore whether or not this is the cause of the observed backscatter offset between the two, we need to mask out the pixels in the PC dataset that are masked in the ASF dataset. \n",
    "\n",
    "In order to do this, first we must downsample the PC dataset to match the spatial resolution of the ASF dataset. There are multiple xarray methods that could be used but here we will use the `xr.interp_like()` method because we would like the PC x and y dimensions to match the ASF dimensiosn exactly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e9560a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_subset = asf_subset.rename({\"acq_date\": \"time\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec91a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_subset.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70023721-3032-4f7d-9e7e-310d7d85c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_downsample = pc_subset.interp_like(asf_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff00257-a320-45db-993d-a58efae6fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "665af539-89e9-4fe6-82a4-06a2ecd05970",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_mask = xr.where(asf_subset[[\"vh\", \"vv\"]].notnull(), pc_downsample, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09c418-dea4-4d7e-83ae-bfbddf964562",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460b6a0-0467-4caa-8f11-a4d05e12af3b",
   "metadata": {},
   "source": [
    "Oops, this isn't what we want. Now we have a 5-dimensional object instead of a 4-dimensional object, because the dimensions of the `asf_subset` object were broadcast onto the `pc_downsample` object, meaning that we have both a `time` and a `acq_date` object.\n",
    "\n",
    "Let's go back and try to fix this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab7b81-d137-4f50-aaaa-988e2e5bc844",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_downsample.isel(time=0).time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2ba75-1874-4cc1-9118-c935e68fdd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_subset.isel(time=0).time.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e5f560-442d-462c-a120-5ffba9ef3f18",
   "metadata": {},
   "source": [
    "Okay, so we need to take the time off of the `pc_downsample` time coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a1eca8c7-a543-4bfe-9484-c9a575ad7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_downsample.coords[\"time\"] = pc_downsample.time.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee6d95-c03c-4cab-bfe7-072cf644bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_downsample.coords.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d234547",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_subset.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d540c",
   "metadata": {},
   "source": [
    "## TODO\n",
    "This didn't throw an error before but does now (xarray: `'2024.10.0'`), fix later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20f4c9-6bcc-491a-ad23-860a9c856a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_subset.coords.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e6339c-054d-4958-92da-5fd90a246de2",
   "metadata": {},
   "source": [
    "Now let's try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd0436-6b8b-40aa-8e2e-9b59443a6d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_mask = xr.where(asf_subset.notnull(), pc_downsample, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f1f95-823d-45de-896a-83f34cf8d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d07c88-faa0-45cb-a1ed-8571ce53ce8c",
   "metadata": {},
   "source": [
    "Great! Looks like its working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a8c2ef-5224-47df-ab18-99f553be3eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e781af0-e0f7-4882-9bf3-58d2775d0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aadaa7-5bf0-4d60-bec0-e6b7889f65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "s1_tools.power_to_db(asf_subset.vv.mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=ax, color=\"blue\", linestyle=\"None\", marker=\"o\", markersize=5, label=\"ASF\"\n",
    ")\n",
    "s1_tools.power_to_db(pc_mask[\"vv\"].mean(dim=[\"x\", \"y\"], skipna=True)).plot(\n",
    "    x=\"time\", ax=ax, color=\"red\", linestyle=\"None\", marker=\"o\", markersize=5, label=\"PC\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea760d5e-cb07-4b63-a622-293491c724e8",
   "metadata": {},
   "source": [
    "## Break up by asc, desc pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d4f6d-429d-430b-baa3-e487a07313f8",
   "metadata": {},
   "source": [
    "Use `xr.where()` to subset datasets by orbital pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37fdb6a-d494-419c-90fe-bd28cb44e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b31d4260-e05b-417d-8afb-1809a45178f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_desc = asf_subset.where(asf_subset[\"orbital_dir\"] == \"desc\", drop=True)\n",
    "asf_asc = asf_subset.where(asf_subset[\"orbital_dir\"] == \"asc\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de5cd9-f374-4b68-a7b3-e82c80487a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asf_asc.vv.mean(dim=['x','y']).plot(marker='o', linestyle='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f82632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_subset = pc_subset.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7b5fc52-eafb-4be7-90e5-452b3f684cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_desc = pc_subset.where(pc_subset[\"sat:orbit_state\"] == \"descending\", drop=True)\n",
    "pc_asc = pc_subset.where(pc_subset[\"sat:orbit_state\"] == \"ascending\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945d99a-b9ff-4bb9-83c0-eb62d9827c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(16, 8))\n",
    "\n",
    "s1_tools.power_to_db(asf_desc.vv.mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=axs[0],\n",
    "    color=\"blue\",\n",
    "    linestyle=\"None\",\n",
    "    marker=\"+\",\n",
    "    markersize=5,\n",
    "    label=\"ASF VV desc\",\n",
    ")\n",
    "s1_tools.power_to_db(pc_desc.vv.mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    "    linestyle=\"None\",\n",
    "    marker=\"+\",\n",
    "    markersize=5,\n",
    "    label=\"PC VV desc\",\n",
    ")\n",
    "s1_tools.power_to_db(asf_asc.vv.mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=axs[0],\n",
    "    color=\"blue\",\n",
    "    linestyle=\"None\",\n",
    "    marker=\"o\",\n",
    "    markersize=5,\n",
    "    label=\"ASF VV asc\",\n",
    ")\n",
    "s1_tools.power_to_db(pc_asc.vv.mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=axs[0],\n",
    "    color=\"red\",\n",
    "    linestyle=\"None\",\n",
    "    marker=\"o\",\n",
    "    markersize=5,\n",
    "    label=\"PC VV asc\",\n",
    ")\n",
    "axs[0].legend(loc=\"lower right\")\n",
    "axs[0].set_xlabel(\"Acquisition date\")\n",
    "axs[0].set_ylabel(\"Backscatter (sigma-nought) (dB)\")\n",
    "axs[0].set_title(\"VV\")\n",
    "\n",
    "s1_tools.power_to_db(asf_desc.vh.mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=axs[1],\n",
    "    color=\"blue\",\n",
    "    linestyle=\"None\",\n",
    "    marker=\"+\",\n",
    "    markersize=5,\n",
    "    label=\"ASF VH desc\",\n",
    ")\n",
    "s1_tools.power_to_db(pc_desc.vh.mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=axs[1],\n",
    "    color=\"red\",\n",
    "    linestyle=\"None\",\n",
    "    marker=\"+\",\n",
    "    markersize=5,\n",
    "    label=\"PC VH desc\",\n",
    ")\n",
    "s1_tools.power_to_db(asf_asc.vh.mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=axs[1],\n",
    "    color=\"blue\",\n",
    "    linestyle=\"None\",\n",
    "    marker=\"o\",\n",
    "    markersize=5,\n",
    "    label=\"ASF VH asc\",\n",
    ")\n",
    "s1_tools.power_to_db(pc_asc.vh.mean(dim=[\"x\", \"y\"])).plot(\n",
    "    ax=axs[1],\n",
    "    color=\"red\",\n",
    "    linestyle=\"None\",\n",
    "    marker=\"o\",\n",
    "    markersize=5,\n",
    "    label=\"PC VH asc\",\n",
    ")\n",
    "axs[1].legend(loc=\"lower right\")\n",
    "axs[1].set_xlabel(\"Acquisition date\")\n",
    "axs[1].set_ylabel(\"Backscatter (sigma-nought) (dB)\")\n",
    "axs[1].set_title(\"VH\")\n",
    "\n",
    "fig.suptitle(\n",
    "    \"Comparison of backscatter values from ASF-processed and PC-processed Sentinel-1 RTC imagery\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d724b3-43c7-44fd-98d9-7f103211e2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEST_geospatial_datacube_book_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
