{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1cbba21-1acd-42df-8642-d03abe72c7b2",
   "metadata": {},
   "source": [
    "# 2. Inspect and organize S1-RTC data processed by ASF\n",
    "\n",
    "Now that we have read in and organized the stack of Sentinel-1 RTC images, this notebook will demonstrate preliminary dataset inspection. \n",
    "\n",
    "## Learning goals\n",
    "\n",
    "**Techniques:**\n",
    "\n",
    "- Comparing raster images\n",
    "- Using `xr.groupby()` for [grouped statistics](https://docs.xarray.dev/en/stable/user-guide/groupby.html)\n",
    "- Simple raster calculations\n",
    "- Indexing and selection\n",
    "- Visualizing multiple facets of the data using `FacetGrid`\n",
    "- Reorganizing data with `xr.Dataset.reindex()`\n",
    "\n",
    "**Science concepts:**\n",
    "\n",
    "- Dataset inspection and evaluation\n",
    "\n",
    "\n",
    "### ASF Data Access\n",
    "\n",
    "You can download the RTC-processed backscatter time series [here](https://zenodo.org/record/7236413#.Y1rNi37MJ-0). For more detail, see [tutorial data](../background/tutorial_data.md#sentinel-1-rtc-datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a350ae-8389-4bc6-bb94-a320b6ce3f9b",
   "metadata": {},
   "source": [
    "## Software and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f4a3f-1adc-4f61-979a-94ec5de93f38",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%xmode minimal\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rioxarray as rio\n",
    "import warnings\n",
    "import xarray as xr\n",
    "\n",
    "import s1_tools\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed3840e-f4a6-4bb3-ad23-1e83a0e5aa0b",
   "metadata": {},
   "source": [
    "## A. Read + prepare data\n",
    "\n",
    "We'll go through the steps shown in [metadata wrangling](2_wrangle_metadata.ipynb), but this time,  combined into one function from `s1_tools`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac699f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_vrt_path = '../data/vrt_files/s1_stackVV.vrt'\n",
    "vh_vrt_path = '../data/vrt_files/s1_stackVH.vrt' \n",
    "ls_vrt_path = '../data/vrt_files/s1_stackLS.vrt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43986980",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_data_cube = s1_tools.metadata_processor(vv_path= vv_vrt_path,\n",
    "                                            vh_path= vh_vrt_path,\n",
    "                                            ls_path= ls_vrt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d54aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_data_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9c132",
   "metadata": {},
   "source": [
    "Until now, we've kept the full spatial extent of the dataset. This hasn't been a problem because all of our operations have been lazy. Now, we'd like to start analyzing and visualizing the dataset so we will subset the data cube to a smaller area of interest.\n",
    "\n",
    "Later notebooks use a different Sentinel-1 RTC dataset that is accessed for a smaller area of interest. We'll clip the current data cube to that spatial footprint now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ae5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read vector data \n",
    "pc_aoi = gpd.read_file(\n",
    "    \"https://github.com/e-marshall/sentinel1_rtc/raw/main/hma_rtc_aoi.geojson\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ad582",
   "metadata": {},
   "source": [
    "Check the CRS and ensure it matches that of the raster data cube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4e708f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert asf_data_cube.rio.crs == pc_aoi.crs, f'Expected: {asf_data_cube.rio.crs}, received: {pc_aoi.crs}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f883fddf",
   "metadata": {},
   "source": [
    "Clip the raster data cube by the extent of the vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b7a85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube = asf_data_cube.rio.clip(pc_aoi.geometry,\n",
    "                                      pc_aoi.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765626a",
   "metadata": {},
   "source": [
    "Persist the dataset in memory so that later operations will be more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0266a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube= clipped_cube.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b28ee7",
   "metadata": {},
   "source": [
    "Great, we've gone from an object where each 3-d variable is ~ 90 GB to one where each 3-d variable is ~45 MB, this will be much easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14382448",
   "metadata": {},
   "source": [
    "## B. Initial visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d211bb6-92b7-42a8-84d1-8b919223db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timestep(input_arr, time_step_int):\n",
    "    \"\"\"plots VV and VH polarizations of a given dataset at a given time step\"\"\"\n",
    "    date = input_arr.isel(acq_date=time_step_int).acq_date.dt.date.data\n",
    "    fig, axs = plt.subplots(ncols=3, figsize=(24, 7))\n",
    "\n",
    "    input_arr.isel(acq_date=time_step_int).ls.plot(ax=axs[0])\n",
    "    s1_tools.power_to_db(input_arr.isel(acq_date=time_step_int).vv).plot(\n",
    "        ax=axs[1], cmap=plt.cm.Greys_r\n",
    "    )\n",
    "    s1_tools.power_to_db(input_arr.isel(acq_date=time_step_int).vh).plot(\n",
    "        ax=axs[2], cmap=plt.cm.Greys_r\n",
    "    )\n",
    "    fig.suptitle(\n",
    "        f\"Layover-shadow mask (L), VV (C) and VH (R) backscatter {str(input_arr.isel(acq_date=time_step_int).acq_date.data)[:-19]}\"\n",
    "    )\n",
    "    axs[0].set_title(f\"{date} layover-shadow map\")\n",
    "    axs[1].set_title(f\"{date} VV backscatter\")\n",
    "    axs[2].set_title(f\"{date} VH backscatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36345896-8b1e-4823-aac8-092c81190ac8",
   "metadata": {},
   "source": [
    "## Layover-shadow mask\n",
    "\n",
    "Each RTC image comes with a geotiff file containing a layover-shadow mask. This can help to understand missing data you might see in the imagery files. The layover shadow masks are coded to represent a number of different types of pixels:\n",
    "\n",
    "The following information is copied from the README file that accompanies each scene: \n",
    "\n",
    "```{**Layover-shadow mask**}\n",
    "\n",
    "The layover/shadow mask indicates which pixels in the RTC image have been affected by layover and shadow. This layer is tagged with _ls_map.tif\n",
    "\n",
    "The pixel values are generated by adding the following values together to indicate which layover and shadow effects are impacting each pixel:\n",
    "0.  Pixel not tested for layover or shadow\n",
    "1.  Pixel tested for layover or shadow\n",
    "2.  Pixel has a look angle less than the slope angle\n",
    "4.  Pixel is in an area affected by layover\n",
    "8.  Pixel has a look angle less than the opposite of the slope angle\n",
    "16. Pixel is in an area affected by shadow\n",
    "\n",
    "There are 17 possible different pixel values, indicating the layover, shadow, and slope conditions present added together for any given pixel._\n",
    "\n",
    "The values in each cell can range from 0 to 31:\n",
    "0.  Not tested for layover or shadow\n",
    "1.  Not affected by either layover or shadow\n",
    "3.  Look angle < slope angle\n",
    "5.  Affected by layover\n",
    "7.  Affected by layover; look angle < slope angle\n",
    "9.  Look angle < opposite slope angle\n",
    "11. Look angle < slope and opposite slope angle\n",
    "13. Affected by layover; look angle < opposite slope angle\n",
    "15. Affected by layover; look angle < slope and opposite slope angle\n",
    "17. Affected by shadow\n",
    "19. Affected by shadow; look angle < slope angle\n",
    "21. Affected by layover and shadow\n",
    "23. Affected by layover and shadow; look angle < slope angle\n",
    "25. Affected by shadow; look angle < opposite slope angle\n",
    "27. Affected by shadow; look angle < slope and opposite slope angle\n",
    "29. Affected by shadow and layover; look angle < opposite slope angle\n",
    "31. Affected by shadow and layover; look angle < slope and opposite slope angle\n",
    "\n",
    "```\n",
    "\n",
    "The ASF RTC image [product guide](https://hyp3-docs.asf.alaska.edu/guides/rtc_product_guide/) has detailed descriptions of how the data is processed and what is included in the processed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6c834-2737-478d-985e-540a2226a3ec",
   "metadata": {},
   "source": [
    "### Quick visualization\n",
    "\n",
    "Let's look at VV and VH backscatter and the layover-shadow mask for a single time step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d9492-3c57-4bef-868f-307c3d1d3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timestep(clipped_cube, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1894f454",
   "metadata": {},
   "source": [
    "The `layover-shadow` variable provides categorical information. We can use a more appropriate colormap for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a17bb37f-81b8-44e7-9db5-d7e05cd18e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cmap = plt.colormaps[\"gist_ncar\"].resampled(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab119e0-fde2-4da9-be6b-221b38a32d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(18, 9))\n",
    "\n",
    "clipped_cube.isel(acq_date=10).ls.plot(ax=axs[0], vmax=22, vmin=1, cmap=cat_cmap)\n",
    "clipped_cube.isel(acq_date=11).ls.plot(ax=axs[1], vmax=22, vmin=1, cmap=cat_cmap);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05454a5d-373f-4620-aba6-cd1fe2ff0820",
   "metadata": {},
   "source": [
    "It looks like there are areas affected by different types of distortion on different dates. For example, in the lower left quadrant, there is a region that is blue (5 - affected by layover) on 6/7/2021 but much of that area appears to be in radar shadow on 6/10/2021. This pattern is present throughout much of the scene with portions of area that are affected by layover in one acquisition in shadow in the next acquisition. This is due to different viewing geometries on different orbital passes: one of the above scenes was likely collected during an ascending pass and one during a descending.\n",
    "\n",
    "## Orbital direction\n",
    "\n",
    "Sentinel-1 is a right-looking sensor and it images areas on Earth's surface in orbits where it is moving N-S (a descending orbit) and S-N (an ascending orbit). It images the same footprint on both passes but from different directions. The data coverage map below illustrates these directional passes, it can be found online [here](https://asf.alaska.edu/daac/sentinel-1-acquisition-maps/)\n",
    "\n",
    "```{image} ../imgs/slc_coverage_asf.png\n",
    ":align center\n",
    "```\n",
    "ASF Sentinel-1 Cumulative coverage map.\n",
    "\n",
    "In areas of high-relief topography such as the AOI we're using, there can be strong terrain distortion effects such as layover and shadow. The above image shows the layover-shadow map for an ascending and a descending image side-by-side, which is why different areas are affected by layover (5) and shadow (17) in each. \n",
    "\n",
    "Thanks to all the setup work we did in the previous notebook, we can quickly confirm that all of the observations were taken at two times of day, corresponding to ascending and descending passes of the satellite, and that the time steps shown above were taken at different times of day.\n",
    "\n",
    ":::{note}\n",
    "The acquisition time of Sentinel-1 images is not in local time.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c599891",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hour of day of acquisition 10: ',clipped_cube.isel(acq_date = 10).acq_date.dt.hour.data)\n",
    "print('Hour of day of acquisition 11: ', clipped_cube.isel(acq_date = 11).acq_date.dt.hour.data)\n",
    "clipped_cube.acq_date.dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86061414",
   "metadata": {},
   "source": [
    "### Is a pass ascending or descending?\n",
    "\n",
    "While it is simple to determine one pass from another, it is not always straightforward to know if a pass is ascending or descending. The timing of these passes depends on the location on earth of the image. \n",
    "\n",
    "In the location covered by this dataset, ascending passes correspond to an acquisition time roughly 0:00 and descending passes correspond to approximately 12:00."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a7d5ab",
   "metadata": {},
   "source": [
    "### Assign orbital direction as a coordinate\n",
    "\n",
    "This is another example of time-varying metadata, so it should be stored as a coordinate variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1ee971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube.coords['orbital_dir'] = ('acq_date', xr.where(clipped_cube.acq_date.dt.hour.data== 0, 'asc','desc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1761a-159d-4be0-873d-1d2638dd1662",
   "metadata": {},
   "source": [
    "## Looking at backscatter variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b70fe58-68dc-43b7-8c3e-d4242d5dc1ec",
   "metadata": {},
   "source": [
    "Let's look at how VV and VH backscatter vary over time. Make a new Xarray object that holds the mean backscatter of VV and VH to visualize this more easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0fe898-4d13-4ce0-82b1-135705d81ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean backscatter of both polarizations\n",
    "mean_pol = xr.Dataset({\"vv\": clipped_cube['vv'].mean(\"acq_date\"),\n",
    "                        \"vh\": clipped_cube['vh'].mean(\"acq_date\")})\n",
    "\n",
    "s1_tools.power_to_db(mean_pol).to_array(\"pol\").plot(col=\"pol\", cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a7adca",
   "metadata": {},
   "source": [
    "Notice that the above plot uses Xarray's FacetGrid plotting, which means that we do'nt need to manually set the limits on the colorscale so that they are tied to both sub-plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d41abc9-9d67-4ef7-8a23-ea2699cb8920",
   "metadata": {},
   "source": [
    "Now let's look at how backscatter may vary seasonally for a single polarization (for more on time-related GroupBy operations see the [Xarray User Guide](https://docs.xarray.dev/en/stable/user-guide/time-series.html#resampling-and-grouped-operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d932cee5-a9d4-49da-95bc-386dffcad6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube_gb = clipped_cube.groupby(\"acq_date.season\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee55f9-130b-46bd-a4ba-6d5a24669885",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b05f5e-aca3-4ec0-938a-3c775724a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order seasons correctly\n",
    "clipped_cube_gb = clipped_cube_gb.reindex({\"season\": [\"DJF\", \"MAM\", \"JJA\", \"SON\"]})\n",
    "clipped_cube_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a662aa5-eb13-44fe-8c61-c9b38a96338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_ = s1_tools.power_to_db(clipped_cube_gb.vv).plot(col=\"season\", cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f545c1-05c9-4f1e-b82f-5712e2a2f042",
   "metadata": {},
   "source": [
    "Interesting, it looks like the winter and spring composites are relatively similar to one another. There also appears to be a decrease in backscatter moving from spring to summer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4258f-21e0-44b3-91cc-26b4d2730187",
   "metadata": {},
   "source": [
    "## Handling duplicate time steps\n",
    "\n",
    "If we take a closer look at the ASF dataset, we can see that there are a few scenes from identical acquisitions (can see this in `acq_date` and more specifically in `product_id`. Let's examine these and see what's going on, if we want to keep the duplicates: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ee0b0-dfa1-44f9-aab5-40d39eb67ffe",
   "metadata": {},
   "source": [
    "First we'll extract the data_date_id from the Sentinel-1 granule ID: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac02d91-cde5-49fd-8bc9-4781ddee5fa9",
   "metadata": {},
   "source": [
    "The length of the `asf_ids` list is exactly what we'd expect, 103. Let's look at the number of unique elements using [`np.unique()`](https://numpy.org/doc/stable/reference/generated/numpy.unique.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b56acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_take_ids_ls = clipped_cube.data_take_ID.data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "176c8b1c-6d62-416a-b3cd-adaf0b1b3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_take_id_set = np.unique(clipped_cube.data_take_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe2c75-76eb-4ab0-a57e-8aa196636126",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_take_id_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6272673-07fa-4812-931d-8a06c24ea44c",
   "metadata": {},
   "source": [
    "Interesting - it looks like there are only 96 unique elements when we look at the `data_take_id`. Let's figure out which are duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a173cfff-7d26-4dcb-959a-4a868133512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate(input_ls):\n",
    "    return list(set([x for x in input_ls if input_ls.count(x) > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437af3ae-fb46-44e3-92d5-0c1723b51d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ls = duplicate(data_take_ids_ls)\n",
    "duplicate_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a20725-470f-46e2-bdd0-f0e991d324d9",
   "metadata": {},
   "source": [
    "These are the data take IDs that are duplicated in the dataset. We now want to subset the xarray object to only include these data take IDs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e8578-86b9-42e9-8d45-8422b1a96233",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_duplicate_cond = clipped_cube.data_take_ID.isin(duplicate_ls)\n",
    "asf_duplicate_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108127f-8d97-4aaa-8a9a-f5e03f387f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_cube = clipped_cube.where(asf_duplicate_cond == True, drop=True)\n",
    "duplicates_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9271e2b-7ddc-46b5-b27b-bb8c4b2e6c62",
   "metadata": {},
   "source": [
    "Great, now we have a 12-time step xarray object that contains only the duplicate data takes. Let's see what it looks like. We can use `xr.FacetGrid` objects to plot these all at once: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4c86b-0926-4ffc-a00c-8f4a8df1d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = asf_duplicates.vv.plot(col=\"acq_date\", col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a31cb3d-be33-49d9-bc44-54be7c43d125",
   "metadata": {},
   "source": [
    "Oops, we can't use faceting along the `acq_date` dimension here because of the repeated time steps that we want to look at. Xarray does not know how to handle these repeated values when it is creating the small multiples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf872ab-e9d5-4523-a42b-9670e872dcbe",
   "metadata": {},
   "source": [
    "For now we'll ignore the repeated values to visualize what's present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470b731-8162-4061-a257-2bc2539965e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = duplicates_cube.rename_dims({\"acq_date\": \"step\"}).vv.plot(col=\"step\", col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59f9f3c-0b20-4584-a1bc-a784b1451972",
   "metadata": {},
   "source": [
    "Interesting, it looks like there's only really data for the 0, 2, 4, 7 and 9 elements of the list of duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2a896-209b-4a60-85af-b68115181459",
   "metadata": {},
   "source": [
    "To drop these, we need to extract the product ID of each duplicate we'd like to remove, since this is the only variable that is unique among the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80493ec3-b2f2-40ba-a903-5398afef6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_ls = [1, 3, 5, 6, 8, 10, 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a697c-3fcb-43de-8dab-8f3ba2c588f8",
   "metadata": {},
   "source": [
    "We can use xarray's `.isel()` method, `.xr.DataArray.isin()`, `xr.Dataset.where()`, and list comprehension to efficiently subset the time steps we want to keep: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f7bfff9-18f9-421c-a957-9f44c2b69dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_product_id_ls = duplicates_cube.isel(acq_date=drop_ls).product_id.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec34ea-cfac-4b20-98c6-bc67263e3b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_product_id_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abcf6e9-e669-4cef-b611-d9c874012829",
   "metadata": {},
   "source": [
    "Using this list, we want to drop all of the elements of `vrt_full` where product Id is one of the values in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c2b0fe6c-38df-4e3b-9721-95fa269cf3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_cond = ~clipped_cube.product_id.isin(drop_product_id_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "92db6495-7080-4d17-b28e-16968a20ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube = clipped_cube.where(duplicate_cond == True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569ea99-54cf-4439-9a5f-06d0288bae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22671cc4-5e5e-40c1-90d2-2a74290b2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube.to_zarr(\"../data/tutorial2/asf_clipped_cube.zarr\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf82f6-58ba-4257-9da8-b1fe9be9315c",
   "metadata": {},
   "source": [
    "## Wrap up \n",
    "\n",
    "This notebook gives a brief look in to the vast amount of auxiliary data that is contained within this dataset. Making the most and best use of this dataset requires familiarity with the the many different types of information it includes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_datacube_book_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
