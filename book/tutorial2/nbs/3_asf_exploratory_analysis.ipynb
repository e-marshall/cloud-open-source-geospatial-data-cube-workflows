{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1cbba21-1acd-42df-8642-d03abe72c7b2",
   "metadata": {},
   "source": [
    "{{title_s1_3}}\n",
    "\n",
    "Now that we have read in and organized the stack of Sentinel-1 RTC images, let's take a look at the data.\n",
    "\n",
    "::::{tab-set}\n",
    ":::{tab-item} Outline\n",
    "\n",
    "(content.section_A)=\n",
    "**[A. Read and prepare data](#a-read-and-prepare-data)**  \n",
    "- {{a1_s1_nb3}}  \n",
    "\n",
    "(content.section_B)=\n",
    "**[B. Initial data visualization](#b-initial-visualization)**  \n",
    "- {{b1_s1_nb3}}  \n",
    "\n",
    "(content.section_C)=\n",
    "**[C. Orbital directoin](#c-orbital-direction)**  \n",
    "- {{c1_s1_nb3}}\n",
    "- {{c2_s1_nb3}}\n",
    "\n",
    "(content.section_D)=\n",
    "**[D. Examine backscatter variability](#d-examine-backscatter-variability)**  \n",
    "- {{d1_s1_nb3}}\n",
    "\n",
    "(content.section_E)=\n",
    "**[E. Handle duplicate time steps](#e-handling-duplicate-time-steps)**\n",
    "- {{e1_s1_nb3}}\n",
    "- {{e2_s1_nb3}}\n",
    "- {{e3_s1_nb3}}\n",
    "\n",
    ":::\n",
    ":::{tab-item} Learning goals  \n",
    "{{concepts}}\n",
    "- Spatial joins of raster and vector data.  \n",
    "- Visualize raster data.  \n",
    "- Use raster metadata to aid interpretation of backscatter imagery.  \n",
    "- Examine data quality using provided layover-shadow maps.  \n",
    "- Identify and remove duplicate time step observations.  \n",
    "\n",
    "{{techniques}}\n",
    "- Clip raster data cube using vector data with [`rioxarray.clip()`](https://corteva.github.io/rioxarray/html/examples/clip_geom.html).  \n",
    "- Using `xr.groupby()` for [grouped statistics](https://docs.xarray.dev/en/stable/user-guide/groupby.html).  \n",
    "- Reorganizing data with `xr.Dataset.reindex()`.  \n",
    "- Visualizing multiple facets of the data using `FacetGrid`\n",
    "\n",
    "\n",
    ":::\n",
    "::::\n",
    "\n",
    ":::{admonition} ASF Data Access\n",
    "You can download the RTC-processed backscatter time series [here](https://zenodo.org/record/7236413#.Y1rNi37MJ-0). For more detail, see [tutorial data](../background/tutorial_data.md#sentinel-1-rtc-datasets) and the [notebook](1_read_asf_data.ipynb) on reading ASF Sentinel-1 RTC data into memory.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f4a3f-1adc-4f61-979a-94ec5de93f38",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "%xmode minimal\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import rioxarray as rio\n",
    "import warnings\n",
    "import xarray as xr\n",
    "\n",
    "import s1_tools\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "99653d20",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "tutorial2_dir = pathlib.Path(cwd).parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed3840e-f4a6-4bb3-ad23-1e83a0e5aa0b",
   "metadata": {},
   "source": [
    "## A. Read and prepare data\n",
    "\n",
    "We'll go through the steps shown in [metadata wrangling](2_wrangle_metadata.ipynb), but this time,  combined into one function from `s1_tools`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ac699f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_vrt_path = \"../data/vrt_files/s1_stackVV.vrt\"\n",
    "vh_vrt_path = \"../data/vrt_files/s1_stackVH.vrt\"\n",
    "ls_vrt_path = \"../data/vrt_files/s1_stackLS.vrt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43986980",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_data_cube = s1_tools.metadata_processor(\n",
    "    vv_path=vv_vrt_path, vh_path=vh_vrt_path, ls_path=ls_vrt_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d54aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_data_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9c132",
   "metadata": {},
   "source": [
    "### {{a1_s1_nb3}}\n",
    "\n",
    "Until now, we've kept the full spatial extent of the dataset. This hasn't been a problem because all of our operations have been lazy. Now, we'd like to visualize the dataset in ways that require eager instead of lazy computation. We subset the data cube to a smaller area to focus on a location interest to make computation more less computationally-intensive.\n",
    "\n",
    "Later notebooks use a different Sentinel-1 RTC dataset that is accessed for a smaller area of interest. Clip the current data cube to that spatial footprint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "487ae5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read vector data\n",
    "pc_aoi = gpd.read_file(\n",
    "    \"https://github.com/e-marshall/sentinel1_rtc/raw/main/hma_rtc_aoi.geojson\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df69a0a",
   "metadata": {},
   "source": [
    "Visualize location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b48c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_aoi.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ad582",
   "metadata": {},
   "source": [
    "Check the CRS and ensure it matches that of the raster data cube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4e708f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert asf_data_cube.rio.crs == pc_aoi.crs, (\n",
    "    f\"Expected: {asf_data_cube.rio.crs}, received: {pc_aoi.crs}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f883fddf",
   "metadata": {},
   "source": [
    "Clip the raster data cube by the extent of the vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube = asf_data_cube.rio.clip(pc_aoi.geometry, pc_aoi.crs)\n",
    "clipped_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765626a",
   "metadata": {},
   "source": [
    "Persist the dataset in memory so that later operations will be more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0266a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube = clipped_cube.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b28ee7",
   "metadata": {},
   "source": [
    "Great, we've gone from an object where each 3-d variable is ~ 90 GB to one where each 3-d variable is ~45 MB, this will be much easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14382448",
   "metadata": {},
   "source": [
    "## B. Initial data visualization\n",
    "\n",
    "Define a function to visualize backscatter imagery for VV and VH polarizations and the layover-shadow at a given point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4d211bb6-92b7-42a8-84d1-8b919223db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timestep(input_arr:xr.DataArray, time_step_int:int):\n",
    "    \"\"\"plots VV and VH polarizations of a given dataset at a given time step\"\"\"\n",
    "    date = input_arr.isel(acq_date=time_step_int).acq_date.dt.date.data\n",
    "    fig, axs = plt.subplots(ncols=3, figsize=(24, 7))\n",
    "\n",
    "    input_arr.isel(acq_date=time_step_int).ls.plot(ax=axs[0])\n",
    "    s1_tools.power_to_db(input_arr.isel(acq_date=time_step_int).vv).plot(\n",
    "        ax=axs[1], cmap=plt.cm.Greys_r\n",
    "    )\n",
    "    s1_tools.power_to_db(input_arr.isel(acq_date=time_step_int).vh).plot(\n",
    "        ax=axs[2], cmap=plt.cm.Greys_r\n",
    "    )\n",
    "    fig.suptitle(\n",
    "        f\"Layover-shadow mask (L), VV (C) and VH (R) backscatter {str(input_arr.isel(acq_date=time_step_int).acq_date.data)[:-19]}\"\n",
    "    )\n",
    "    axs[0].set_title(f\"{date} layover-shadow map\")\n",
    "    axs[1].set_title(f\"{date} VV backscatter\")\n",
    "    axs[2].set_title(f\"{date} VH backscatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36345896-8b1e-4823-aac8-092c81190ac8",
   "metadata": {},
   "source": [
    "### {{b1_s1_nb3}}\n",
    "\n",
    "Each Sentinel-1 RTC scene directory contains a GeoTIFF file containing a layover-shadow mask. This can help to understand missing data you might see in the imagery files. The layover shadow masks are coded to represent a number of different types of pixels:\n",
    "\n",
    "The following information is copied from the README file that accompanies each scene: \n",
    "\n",
    "```{**Layover-shadow mask**}\n",
    "\n",
    "The layover/shadow mask indicates which pixels in the RTC image have been affected by layover and shadow. This layer is tagged with _ls_map.tif\n",
    "\n",
    "The pixel values are generated by adding the following values together to indicate which layover and shadow effects are impacting each pixel:\n",
    "0.  Pixel not tested for layover or shadow\n",
    "1.  Pixel tested for layover or shadow\n",
    "2.  Pixel has a look angle less than the slope angle\n",
    "4.  Pixel is in an area affected by layover\n",
    "8.  Pixel has a look angle less than the opposite of the slope angle\n",
    "16. Pixel is in an area affected by shadow\n",
    "\n",
    "There are 17 possible different pixel values, indicating the layover, shadow, and slope conditions present added together for any given pixel._\n",
    "\n",
    "The values in each cell can range from 0 to 31:\n",
    "0.  Not tested for layover or shadow\n",
    "1.  Not affected by either layover or shadow\n",
    "3.  Look angle < slope angle\n",
    "5.  Affected by layover\n",
    "7.  Affected by layover; look angle < slope angle\n",
    "9.  Look angle < opposite slope angle\n",
    "11. Look angle < slope and opposite slope angle\n",
    "13. Affected by layover; look angle < opposite slope angle\n",
    "15. Affected by layover; look angle < slope and opposite slope angle\n",
    "17. Affected by shadow\n",
    "19. Affected by shadow; look angle < slope angle\n",
    "21. Affected by layover and shadow\n",
    "23. Affected by layover and shadow; look angle < slope angle\n",
    "25. Affected by shadow; look angle < opposite slope angle\n",
    "27. Affected by shadow; look angle < slope and opposite slope angle\n",
    "29. Affected by shadow and layover; look angle < opposite slope angle\n",
    "31. Affected by shadow and layover; look angle < slope and opposite slope angle\n",
    "\n",
    "```\n",
    "\n",
    "The ASF RTC image [product guide](https://hyp3-docs.asf.alaska.edu/guides/rtc_product_guide/) has detailed descriptions of how the data is processed and what is included in the processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d9492-3c57-4bef-868f-307c3d1d3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timestep(clipped_cube, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1894f454",
   "metadata": {},
   "source": [
    "The `layover-shadow` variable provides categorical information. We can use a more appropriate colormap for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab119e0-fde2-4da9-be6b-221b38a32d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cmap = plt.colormaps[\"gist_ncar\"].resampled(20)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(18, 9))\n",
    "\n",
    "clipped_cube.isel(acq_date=10).ls.plot(ax=axs[0], vmax=22, vmin=1, cmap=cat_cmap)\n",
    "clipped_cube.isel(acq_date=11).ls.plot(ax=axs[1], vmax=22, vmin=1, cmap=cat_cmap);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e8886",
   "metadata": {},
   "source": [
    "It looks like there are areas affected by different types of distortion on different dates. For example, in the lower left quadrant, there is a region that is blue (5 - affected by layover) on 6/7/2021 but much of that area appears to be in radar shadow on 6/10/2021. This pattern is present throughout much of the scene with portions of area that are affected by layover in one acquisition in shadow in the next acquisition. This is due to the viewing geometries of different orbital passes: one of the above scenes  was collected during an ascending pass of the satellite and one during a descending pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05454a5d-373f-4620-aba6-cd1fe2ff0820",
   "metadata": {},
   "source": [
    "## C. Orbital direction\n",
    "\n",
    "Sentinel-1 is a right-looking sensor and it images areas on Earth's surface in orbits when it is moving N-S (a descending orbit) and S-N (an ascending orbit). It images the same footprint on both passes but from different directions. The data coverage map below illustrates these directional passes, it can be found online [here](https://asf.alaska.edu/daac/sentinel-1-acquisition-maps/)\n",
    "\n",
    "```{image} ../imgs/slc_coverage_asf.png\n",
    ":align center\n",
    "```\n",
    "ASF Sentinel-1 Cumulative coverage map.\n",
    "\n",
    "In areas of high-relief topography such as the area we're observing, there can be strong terrain distortion effects such as layover and shadow. These are some of the distortions that RTC processing corrects, but sometimes it is not possible to reliably extract backscatter in the presence of strong distortions. The above image shows the layover-shadow map for an ascending and a descending image side-by-side, which is why different areas are affected by layover (5) and shadow (17) in each. \n",
    "\n",
    "Thanks to all the setup work we did in the previous notebook, we can quickly confirm that all of the observations were taken at two times of day, corresponding to ascending and descending passes of the satellite, and that the time steps shown above were taken at different times of day.\n",
    "\n",
    ":::{note}\n",
    "The acquisition time of Sentinel-1 images is not in local time.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c599891",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Hour of day of acquisition 10: \",\n",
    "    clipped_cube.isel(acq_date=10).acq_date.dt.hour.data,\n",
    ")\n",
    "print(\n",
    "    \"Hour of day of acquisition 11: \",\n",
    "    clipped_cube.isel(acq_date=11).acq_date.dt.hour.data,\n",
    ")\n",
    "clipped_cube.acq_date.dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86061414",
   "metadata": {},
   "source": [
    "### {{c1_s1_nb3}}\n",
    "\n",
    "While it is simple to determine one pass from another, it is not always straightforward to know if a pass is ascending or descending. The timing of these passes depends on the location on earth of the image. \n",
    "\n",
    "In the location covered by this dataset, ascending passes correspond to an acquisition time roughly 0:00 UTC and descending passes correspond to approximately 12:00 UTC. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a7d5ab",
   "metadata": {},
   "source": [
    "### {{c2_s1_nb3}}\n",
    "This is another example of time-varying metadata, so it should be stored as a coordinate variable. Use [`xr.where()`](https://docs.xarray.dev/en/stable/generated/xarray.where.html) to assign the correct orbital direction value depending on an observation's acquisition time and then assign it as a coordinate variable to the clipped raster data cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1ee971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube.coords[\"orbital_dir\"] = (\n",
    "    \"acq_date\",\n",
    "    xr.where(clipped_cube.acq_date.dt.hour.data == 0, \"asc\", \"desc\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1761a-159d-4be0-873d-1d2638dd1662",
   "metadata": {},
   "source": [
    "## D. Examine backscatter variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa7aa7",
   "metadata": {},
   "source": [
    "Let's look at how VV and VH backscatter vary over time. Make a new Xarray object that holds the mean backscatter of VV and VH to visualize this more easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9c969cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean backscatter of both polarizations\n",
    "mean_pol = xr.Dataset(\n",
    "    {\n",
    "        \"vv\": clipped_cube[\"vv\"].mean(\"acq_date\"),\n",
    "        \"vh\": clipped_cube[\"vh\"].mean(\"acq_date\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b70fe58-68dc-43b7-8c3e-d4242d5dc1ec",
   "metadata": {},
   "source": [
    "Convert the power measurements provided in the raster data cube to decibels and then use Xarray [FacetGrid](https://docs.xarray.dev/en/latest/generated/xarray.plot.FacetGrid.html) plotting to make a two-column plot of mean backscatter for VV and VH. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0fe898-4d13-4ce0-82b1-135705d81ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = s1_tools.power_to_db(mean_pol).to_array(\"pol\").plot(col=\"pol\", \n",
    "                                                        cmap=plt.cm.Greys_r,\n",
    "                                                        cbar_kwargs={\"label\":\"dB\"},\n",
    "                                                        )\n",
    "for i in range(len(a.axs[0])):\n",
    "    a.axs[0][i].set_xlabel(None)\n",
    "    a.axs[0][i].tick_params(axis='x', labelrotation=45)\n",
    "a.axs[0][0].set_ylabel(None)\n",
    "a.fig.suptitle('Mean backscatter over time of dual-pol (VV) and cross-pol (VH) imagery',\n",
    "               y=1.02)\n",
    "a.fig.supylabel('Y-coordinate of projection (m)')\n",
    "a.fig.supxlabel('X-coordinate of projection (m)', y=-0.15)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc63f9bd",
   "metadata": {},
   "source": [
    "The area that we're looking at is in the mountainous region on the border between the Sikkim region of India and China. There are four north-facing glacier visible in the image, each with a lake at the toe. Bodies of water like lakes tend to appear dark in C-band SAR images because water is smooth with respect to the wavelength of the signal, meaning that most of the emitted signal is scattered away from the sensor. where surfaces that are rough at the scale of C-band wavelength, more signal is returned to the sensor and the backscatter image is brighter. For much more detail on interpreting SAR imagery, see the resources linked in the Sentinel-1 section of the [tutorial data](../../background/tutorial_data.md) page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d41abc9-9d67-4ef7-8a23-ea2699cb8920",
   "metadata": {},
   "source": [
    "### {{d1_s1_nb1}}\n",
    "\n",
    "Now let's look at how backscatter may vary seasonally for a single polarization (for more on time-related GroupBy operations see the [Xarray User Guide](https://docs.xarray.dev/en/stable/user-guide/time-series.html#resampling-and-grouped-operations). This is an example of a 'split-apply-combine' operation, where a dataset is split into groups (in this case, time steps are split into seasons), an operation is applied (in this case, the mean is calculated) and then the groups are combined into a new object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d932cee5-a9d4-49da-95bc-386dffcad6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube_gb = clipped_cube.groupby(\"acq_date.season\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02768bb",
   "metadata": {},
   "source": [
    "The temporal dimension of the new object has an element for each season rather than an element for each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee55f9-130b-46bd-a4ba-6d5a24669885",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b05f5e-aca3-4ec0-938a-3c775724a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order seasons correctly\n",
    "clipped_cube_gb = clipped_cube_gb.reindex({\"season\": [\"DJF\", \"MAM\", \"JJA\", \"SON\"]})\n",
    "clipped_cube_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f020fd",
   "metadata": {},
   "source": [
    "Visualize mean backscatter in each season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a662aa5-eb13-44fe-8c61-c9b38a96338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_ = s1_tools.power_to_db(clipped_cube_gb.vv).plot(col=\"season\", cmap=plt.cm.Greys_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588f89c",
   "metadata": {},
   "source": [
    "The glacier surfaces appear much darker during the summer months than other seasons, especially in the lower reaches of the glaciers. Like the lake surfaces above, this suggests largely specular scattering where no signal returns in the incident direction. It could be that during the summer months, enough liquid water is present at the glacier surface to produce this scattering. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4258f-21e0-44b3-91cc-26b4d2730187",
   "metadata": {},
   "source": [
    "## E. Handling duplicate time steps\n",
    "\n",
    "If we take a closer look at the ASF dataset, we can see that there are a few scenes from identical acquisitions (this is apparent in `acq_date` and more specifically in `product_id`). Let's examine these and see what's going on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ee0b0-dfa1-44f9-aab5-40d39eb67ffe",
   "metadata": {},
   "source": [
    "First we'll extract the `data_take_ID` from the Sentinel-1 granule ID: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube.data_take_ID.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac02d91-cde5-49fd-8bc9-4781ddee5fa9",
   "metadata": {},
   "source": [
    "Let's look at the number of unique elements using [`np.unique()`](https://numpy.org/doc/stable/reference/generated/numpy.unique.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b56acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_take_ids_ls = clipped_cube.data_take_ID.data.tolist()\n",
    "data_take_id_set = np.unique(clipped_cube.data_take_ID)\n",
    "len(data_take_id_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6272673-07fa-4812-931d-8a06c24ea44c",
   "metadata": {},
   "source": [
    "### {{e1_s1_nb3}}\n",
    "\n",
    "Interesting - it looks like there are only 96 unique elements. Let's figure out which are duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a173cfff-7d26-4dcb-959a-4a868133512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate(input_ls):\n",
    "    return list(set([x for x in input_ls if input_ls.count(x) > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437af3ae-fb46-44e3-92d5-0c1723b51d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ls = duplicate(data_take_ids_ls)\n",
    "duplicate_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a20725-470f-46e2-bdd0-f0e991d324d9",
   "metadata": {},
   "source": [
    "These are the data take IDs that are duplicated in the dataset. We now want to subset the xarray object to only include these data take IDs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e8578-86b9-42e9-8d45-8422b1a96233",
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_duplicate_cond = clipped_cube.data_take_ID.isin(duplicate_ls)\n",
    "asf_duplicate_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108127f-8d97-4aaa-8a9a-f5e03f387f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_cube = clipped_cube.where(asf_duplicate_cond == True, drop=True)\n",
    "duplicates_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9271e2b-7ddc-46b5-b27b-bb8c4b2e6c62",
   "metadata": {},
   "source": [
    "### {{e2_s1_nb3}}\n",
    "\n",
    "Great, now we have a 12-time step Xarray object that contains only the duplicate data takes. Let's see what it looks like. We can use `xr.FacetGrid` objects to plot all of the arrays at once.\n",
    "\n",
    "Before we make a FacetGrid plot, we need to make a change to the dataset. FacetGrid takes a column and expands the levels of the provided dimension into individual sub-plots (a small multiples plot). We're looking at the duplicate time steps, meaning the elements of the `acq_date` dimension are non-unique. FacetGrid expects unique values along the specified coordinate array. If we were to directly call: \n",
    "```python\n",
    "fg = duplicates_cube.vv.plot(col=\"acq_date\", col_wrap=4)\n",
    "``` \n",
    "We would receive the following error: \n",
    "```\n",
    "ValueError: Coordinates used for faceting cannot contain repeated (nonunique) values.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72209ccb",
   "metadata": {},
   "source": [
    "Renaming the dimensions of `duplicates_cube` with [`xr.rename_dims()`](https://docs.xarray.dev/en/latest/generated/xarray.Dataset.rename_dims.html) demotes the `acq_date` coordinate array to non-dimensional coordinate and replaces it with `step` an array of integers. Because these are unique, we can make a FaceGrid plot with the `step` dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b49cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_cube.rename_dims({'acq_date':'step'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470b731-8162-4061-a257-2bc2539965e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = duplicates_cube.rename_dims({\"acq_date\": \"step\"}).vv.plot(col=\"step\", col_wrap=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59f9f3c-0b20-4584-a1bc-a784b1451972",
   "metadata": {},
   "source": [
    "Interesting, it looks like there's only really data for the 0, 2, 4, 7 and 9 elements of the list of duplicates. It could be that the processing of these files was interrupted and then restarted, producing extra empty arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df27b9cf",
   "metadata": {},
   "source": [
    "### {{e3_s1_nb3}}\n",
    "\n",
    "To drop these arrays, extract the product ID (the only variable that is unique among the duplicates) of each array we'd like to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "80493ec3-b2f2-40ba-a903-5398afef6dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_ls = [1, 3, 5, 6, 8, 10, 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a697c-3fcb-43de-8dab-8f3ba2c588f8",
   "metadata": {},
   "source": [
    "We can use xarray's `.isel()` method, `.xr.DataArray.isin()`, `xr.Dataset.where()`, and list comprehension to efficiently subset the time steps we want to keep: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7bfff9-18f9-421c-a957-9f44c2b69dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_product_id_ls = duplicates_cube.isel(acq_date=drop_ls).product_id.data\n",
    "drop_product_id_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abcf6e9-e669-4cef-b611-d9c874012829",
   "metadata": {},
   "source": [
    "Using this list, we want to drop all of the elements of `clipped_cube` where product Id is one of the values in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c2b0fe6c-38df-4e3b-9721-95fa269cf3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_cond = ~clipped_cube.product_id.isin(drop_product_id_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db6495-7080-4d17-b28e-16968a20ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube = clipped_cube.where(duplicate_cond == True, drop=True)\n",
    "clipped_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4130494d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to use the data cube that we assembled in the previous notebooks. We saw various ways that having metadata accessible and attached to the correct dimensions of the data cube made learning about teh dataset much smoother and more efficient than it would otherwise be. \n",
    "\n",
    "In the next notebook, we'll work with a different Sentinel-1 RTC dataset. We'll write this dataset to disk in order to use it in the final notebook of the tutorial, a comparison of two datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22671cc4-5e5e-40c1-90d2-2a74290b2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_cube.to_zarr(\"../data/s1_asf_clipped_cube.zarr\", mode=\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_datacube_book_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
