{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5a73d7-6a11-40d8-9efe-43e1cc70e677",
   "metadata": {},
   "source": [
    "{{title_s1_1}}\n",
    "\n",
    "This notebook demonstrates working with Sentinel-1 RTC imagery that has been processed on the [ASF On-Demand server](https://docs.asf.alaska.edu/vertex/manual/) and downloaded locally. \n",
    "\n",
    "The downloaded time series of Sentinel-1 imagery is very large. We demonstrate strategies for reading data of this nature into memory by creating a *virtual copy* of the data. \n",
    "\n",
    ":::{admonition} ASF data access options\n",
    "The steps shown in this notebook involve downloading and extracting large volumes of data. **It is not necessary to do this to follow the rest of the content in the tutorial**. We include the demonstration for the purposes of completeness and to help users who may be in this situation.\n",
    "\n",
    "For more information on different options for downloading data locally, see the [Introduction](../s1_intro.md#different-ways-to-use-this-tutorial).\n",
    ":::\n",
    "\n",
    "::::{tab-set}\n",
    ":::{tab-item} Outline   \n",
    "(content:section_A)=\n",
    "**[A. Prepare to read data into memory](#a-prepare-to-read-data-into-memory)**  \n",
    "- {{a1_s1_nb1}}  \n",
    "- {{a2_s1_nb1}}  \n",
    "\n",
    "(content:section_B)=\n",
    "**[B. Read data](#b-read-data)**  \n",
    "- {{b1_s1_nb1}}  \n",
    ":::\n",
    "\n",
    ":::{tab-item} Learning goals\n",
    "\n",
    "{{concepts}}\n",
    "- Understand local file storage and create virtual datasets from locally stored files\n",
    "- Read larger-than-memory data into memory\n",
    "- Use VRT files to create 3-d Xarray data cubes from stack of 2-d image files\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52885f87",
   "metadata": {},
   "source": [
    "Expand the next cell to see specific packages used in this notebook and relevant system and version information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb32b85-47b7-4e1d-baeb-48af7116ce6e",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "#%xmode minimal\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "import geopandas as gpd\n",
    "import markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e975ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "tutorial2_dir = pathlib.Path(cwd).parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efdc79f",
   "metadata": {},
   "source": [
    "{{break}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b2541",
   "metadata": {},
   "source": [
    "## A. Prepare to read data into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2fbfb",
   "metadata": {},
   "source": [
    "### {{a1_s1_nb1}}\n",
    "\n",
    "After the data is extracted from the compressed files, we have a directory containing sub-directories for each Sentinel-1 image acquisition (scene). Within each sub-directory are all of the files associated with that scene. For more information about the files contained in each directory, see this [section](https://hyp3-docs.asf.alaska.edu/guides/rtc_product_guide/#image-files) of the ASF Sentinel-1 RTC Product Guide.\n",
    "\n",
    "The directory should look like the diagram below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f33c79",
   "metadata": {},
   "source": [
    "```\n",
    ".\n",
    "└── s1_asf_data\n",
    "    ├── S1A_IW_20210502T121414_DVP_RTC30_G_gpuned_1424\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_VH.tif.xml\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_rgb.kmz\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_shape.prj\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7.png.aux.xml\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7.README.md.txt\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_rgb.png.aux.xml\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_rgb.png\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_VV.tif.xml\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7.png\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_rgb.png.xml\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7.png.xml\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_shape.shp\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_VH.tif\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7.log\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_VV.tif\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7.kmz\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_shape.dbf\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_ls_map.tif.xml\n",
    "    │   ├── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_shape.shx\n",
    "    │   └── S1A_IW_20220214T121353_DVP_RTC30_G_gpuned_51E7_ls_map.tif\n",
    "    └── S1A_IW_20210505T000307_DVP_RTC30_G_gpuned_54B1\n",
    "        └── ...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea76c0",
   "metadata": {},
   "source": [
    "To build GDAL VRT files, we need to pass a list of the input datasets. This means that we need to extract the file path to every file associated with each variable (VV, VH and L-S). \n",
    "\n",
    ":::{attention} \n",
    "If you are following along on your own computer, be sure to specify two things:\n",
    "1. Set `path_to_rtcs` to the location of the downloaded files on your own computer.\n",
    "2. Set `timeseries_type` to `'full'` or `'subset'` depending on if you are using the full time series (103 files) or the subset time series (5 files).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8afe4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_type = \"full\"\n",
    "path_to_rtcs = f\"data/{timeseries_type}_timeseries/asf_rtcs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf6dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to directory holding downloaded data\n",
    "s1_asf_data = pathlib.Path(cwd.parent, path_to_rtcs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9bc154",
   "metadata": {},
   "source": [
    "Make a list of all scenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d641245",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_ls = os.listdir(s1_asf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55cd2d",
   "metadata": {},
   "source": [
    "The below function makes a list of all file names across the individual scene directory for VV, VH, ls_map and README files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b36fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fnames(data_path: str, scene_name:str, variable:str):\n",
    "    # Make list of files within each scene directory in data directory\n",
    "    scene_files_ls = os.listdir(os.path.join(data_path, scene_name))\n",
    "\n",
    "    if variable in ['vv','vh']:\n",
    "        scene_files = [fname for fname in scene_files_ls if fname.endswith(f\"_{variable.upper()}.tif\")]\n",
    "    \n",
    "    elif variable == 'ls_map':\n",
    "        scene_files = [fname for fname in scene_files_ls if fname.endswith(f\"_ls_map.tif\")]\n",
    "    \n",
    "    elif variable == 'readme':\n",
    "        scene_files = [file for file in scene_files_ls if file.endswith(\"README.md.txt\")]\n",
    "   \n",
    "    return scene_files\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72424d",
   "metadata": {},
   "source": [
    "Below is the output of `extract_fnames()` for two one scene directory. Note that `os.listdir()` **does not** preserve the order of the subdirectories as listed on disk. This is okay because we will ensure that the files are sorted in chronological order later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b409a588-e769-49d1-b62b-6f585dc9599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_fnames(s1_asf_data, scenes_ls[0], 'vv'))\n",
    "print(extract_fnames(s1_asf_data, scenes_ls[0], 'vh'))\n",
    "print(extract_fnames(s1_asf_data, scenes_ls[0], 'ls_map'))\n",
    "print(extract_fnames(s1_asf_data, scenes_ls[0], 'readme'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09499727",
   "metadata": {},
   "source": [
    "We need to attach the filenames to the path of each file so that we end up with a list of the full paths to the VV and VH band imagery, layover-shadow maps and README files. Within this step, we will also add checks to ensure that the process is doing what we want, which is to create lists of filepaths for each character **with the same order across lists** so that we can combine the lists into a multivariate time series. As noted above, it is okay that the lists are not in chronological order, as long as they are in **the same** order across variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e943c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filepath_lists(asf_s1_data_path: str, variable:str):\n",
    "    \"\"\" For a single variable (vv, vh, ls_map or readme), make list of \n",
    "    full filepath for each file in time series. Also return dates to ensure\n",
    "    extraction happens in correct order for each variable\n",
    "    Return tuple with form (filepaths list, dates list)\"\"\"\n",
    "    scenes_ls = os.listdir(asf_s1_data_path)\n",
    "\n",
    "    fpaths, dates_ls = [],[]\n",
    "\n",
    "    for element in range(len(scenes_ls)):\n",
    "\n",
    "        # Extract filenames of each file of interest\n",
    "        files_of_interest = extract_fnames(asf_s1_data_path, scenes_ls[element], variable)\n",
    "        # Make full path with filename for each variable\n",
    "        path = os.path.join(\n",
    "            asf_s1_data_path, scenes_ls[element], files_of_interest[0]\n",
    "        )\n",
    "        #extract dates to make sure dates are identical across variable lists\n",
    "        date = pathlib.Path(path).stem.split(\"_\")[2]\n",
    "        \n",
    "        dates_ls.append(date)\n",
    "        fpaths.append(path)\n",
    "    \n",
    "    return (fpaths, dates_ls)\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf94ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filenames_dict(rtc_path, variables_ls):\n",
    "\n",
    "    keys, filepaths, dates = [],[],[]\n",
    "    for variable in variables_ls:\n",
    "        keys.append(variable)\n",
    "\n",
    "        filespaths_list, dates_list = make_filepath_lists(rtc_path, variable)\n",
    "        filepaths.append(filespaths_list)\n",
    "        dates.append(dates_list)\n",
    "    \n",
    "    #make dict of variable names (keys) and associated filepaths\n",
    "    filepaths_dict = dict(zip(keys, filepaths))\n",
    "\n",
    "    #make sure that dates are identical across all lists\n",
    "    assert all(lst == dates[0] for lst in dates) == True\n",
    "    #make sure length of each variable list is the same \n",
    "    assert len(list(set([len(v) for k,v in filepaths_dict.items()]))) == 1\n",
    "    \n",
    "\n",
    "\n",
    "    #make dict of variable names (keys) and associated filepaths\n",
    "    filepaths_dict = dict(zip(keys, filepaths))\n",
    "    return filepaths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9cd036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths_dict = create_filenames_dict(s1_asf_data, ['vv','vh','ls_map','readme'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724a7366",
   "metadata": {},
   "source": [
    "`filepaths_dict` has a key for each file type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fabdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3afeecc",
   "metadata": {},
   "source": [
    "The values are the paths to each file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df335f-c7ca-4b0d-8051-c4882942ffbb",
   "metadata": {},
   "source": [
    "### {{a2_s1_nb1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98cd57-07c1-4e7d-ba68-ff20aecd074f",
   "metadata": {},
   "source": [
    "We will be using the `gdalbuildvrt` command. You can find out more about it [here](https://manpages.ubuntu.com/manpages/bionic/man1/gdalbuildvrt.1.html). This command creates a *virtual* GDAL dataset given a list of other GDAL datasets (the Sentinel-1 scenes). `gdalbuildvrt` can make a VRT that either tiles the listed files into a large spatial mosaic, or places them each in a separate band of the VRT. Because we are dealing with a temporal stack of images we want to use the `-separate` flag to place each file into a band of the VRT. </br>\n",
    "\n",
    "Here is where we use the list of file paths we created above. For each variable, write the list of file paths to a `.txt` file which is then passed to `gdalbuildvrt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9646960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vrt_object(fpaths_dict: dict, variable: str, timeseries_type:str):\n",
    "    \"\"\"Function to create VRT files for each variable given a\n",
    "    list of file paths fo that variable.\"\"\"\n",
    "\n",
    "    full_timeseries_data = '../data/full_timeseries'\n",
    "    subset_timeseries_data = '../data/subset_timeseries'\n",
    "\n",
    "    if timeseries_type == 'full':\n",
    "        data_path = full_timeseries_data\n",
    "    elif timeseries_type == 'subset':\n",
    "        data_path = subset_timeseries_data\n",
    "    \n",
    "    #switch 'ls' to match variable name in dict\n",
    "    if variable == \"ls\":\n",
    "        variable = \"ls_map\"\n",
    "    \n",
    "\n",
    "\n",
    "    # Write file paths to txt file\n",
    "    fpath_input_txt = pathlib.Path(data_path, f\"txt_files/s1_{variable}_fpaths.txt\")\n",
    "\n",
    "    # Specify location of vrt file- note that we use\n",
    "    # tutorial2_dir path defined at top of notebook\n",
    "    output_vrt_path = pathlib.Path(data_path, f\"vrt_files/s1_stack_{variable}.vrt\")\n",
    "\n",
    "    # Write file paths to txt file\n",
    "    with open(fpath_input_txt, \"w\") as fp:\n",
    "        for item in fpaths_dict[f\"{variable}\"]:\n",
    "            fp.write(f\"{item}\\n\")\n",
    "\n",
    "    !gdalbuildvrt -separate -input_file_list {fpath_input_txt} {output_vrt_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd4e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_vrt_object(filepaths_dict, \"vv\", timeseries_type)\n",
    "create_vrt_object(filepaths_dict, \"vh\", timeseries_type)\n",
    "create_vrt_object(filepaths_dict, \"ls\", timeseries_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff15f3-68ec-4842-b6ee-4551551fecf4",
   "metadata": {},
   "source": [
    "## B. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca79899",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "359581f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_vv = xr.open_dataset(f\"../data/{timeseries_type}_timeseries/vrt_files/s1_stack_vv.vrt\", chunks=\"auto\")\n",
    "ds_vh = xr.open_dataset(f\"../data/{timeseries_type}_timeseries/vrt_files/s1_stack_vh.vrt\", chunks=\"auto\")\n",
    "ds_ls = xr.open_dataset(f\"../data/{timeseries_type}_timeseries/vrt_files/s1_stack_ls_map.vrt\", chunks=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb8e89-fcd3-4985-9b0e-3c652195969f",
   "metadata": {},
   "source": [
    "Building the `VRT` object assigns every object in the .txt file to a different band. In doing this, we lose the metadata that is associated with the files. The next notebook walks through the steps of reconstructing necessary metadata stored in file names and auxiliary files and attaching it to the Xarray objects read from VRTs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979db2a7",
   "metadata": {},
   "source": [
    "### {{b1_s1_nb1}}\n",
    "\n",
    "```{image} ../imgs/s1_chunks.png\n",
    ":alt chunks_image\n",
    ":align_center\n",
    "```\n",
    "\n",
    "Each variable in `ds` has a total shape of (103, 13379, 1742) and is 89.59 GB. It is chunked so that each chunk is (11, 1536, 1536) and 99 MB, with 1080 total chunks per variable. \n",
    "\n",
    "Depending on your use-case, you may want to adjust the chunking of the object. For example, if you are interested in analyzing variability along the temporal dimension, it might make sense to re-chunk the dataset so that operations along the that dimension are more easily parallelized. For more detail, see the {term}`chunking` discussion in [Relevant Concepts](../../background/relevant_concepts.md) and the [Parallel Computing with Dask](https://docs.xarray.dev/en/stable/user-guide/dask.html) section of the Xarray documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c2ad54",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated reading large data into memory by creating a virtual dataset that references that full dataset without directly reading it. \n",
    "\n",
    "However, we also saw that reading the data in this way produces an object that lacks important metadata. The next notebook will go through the steps of locating and adding relevant metadata to the backscatter data cubes read in this notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_datacube_book_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
